"""
åŒæ­¥ç®¡ç†å™¨

ç»Ÿä¸€ç®¡ç†å¢é‡åŒæ­¥ã€ç¼ºå£æ£€æµ‹å’Œæ•°æ®éªŒè¯åŠŸèƒ½ã€‚
"""

# æ ‡å‡†åº“å¯¼å…¥
import logging
from datetime import date, datetime, timedelta
from typing import Any, Dict, List, Optional

# é¡¹ç›®å†…å¯¼å…¥
from ..config import Config
from ..core import BaseManager, ValidationError, unified_error_handler
from ..data_sources import DataSourceManager
from ..database import DatabaseManager
from ..preprocessor import DataProcessingEngine
from ..utils.progress_bar import (
    create_phase_progress,
    log_error,
    log_phase_complete,
    log_phase_start,
    update_phase_description,
)
from .gap_detector import GapDetector
from .incremental import IncrementalSync
from .validator import DataValidator

logger = logging.getLogger(__name__)


class DataQualityValidator:
    """æ•°æ®è´¨é‡éªŒè¯å™¨"""

    @staticmethod
    def is_valid_financial_data(data: Dict[str, Any]) -> bool:
        """éªŒè¯è´¢åŠ¡æ•°æ®æœ‰æ•ˆæ€§"""
        if not data or not isinstance(data, dict):
            return False

        # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„è´¢åŠ¡æŒ‡æ ‡
        revenue = data.get("revenue", 0)
        net_profit = data.get("net_profit", 0)
        total_assets = data.get("total_assets", 0)

        # è‡³å°‘è¦æœ‰ä¸€ä¸ªéé›¶çš„ä¸»è¦è´¢åŠ¡æŒ‡æ ‡
        return (
            (revenue and revenue > 0)
            or (total_assets and total_assets > 0)
            or (net_profit != 0)  # å‡€åˆ©æ¶¦å¯ä»¥ä¸ºè´Ÿ
        )

    @staticmethod
    def is_valid_valuation_data(data: Dict[str, Any]) -> bool:
        """éªŒè¯ä¼°å€¼æ•°æ®æœ‰æ•ˆæ€§"""
        if not data or not isinstance(data, dict):
            return False

        pe_ratio = data.get("pe_ratio", 0)
        pb_ratio = data.get("pb_ratio", 0)
        market_cap = data.get("market_cap", 0)

        # PE/PBåº”è¯¥ä¸ºæ­£æ•°ä¸”åœ¨åˆç†èŒƒå›´å†…ï¼Œå¸‚å€¼åº”è¯¥å¤§äº0
        return (
            (pe_ratio and 0 < pe_ratio < 1000)
            or (pb_ratio and 0 < pb_ratio < 100)
            or (market_cap and market_cap > 0)
        )

    @staticmethod
    def is_valid_report_date(report_date: str, symbol: str = None) -> bool:
        """éªŒè¯æŠ¥å‘ŠæœŸæœ‰æ•ˆæ€§"""
        try:
            from datetime import datetime

            report_dt = datetime.strptime(report_date, "%Y-%m-%d")
            current_dt = datetime.now()

            # æŠ¥å‘ŠæœŸä¸èƒ½æ˜¯æœªæ¥æ—¥æœŸ
            if report_dt > current_dt:
                return False

            # æŠ¥å‘ŠæœŸä¸èƒ½å¤ªä¹…è¿œï¼ˆæ¯”å¦‚1990å¹´ä»¥å‰ï¼‰
            if report_dt.year < 1990:
                return False

            return True
        except (ValueError, TypeError):
            return False

    @staticmethod
    def is_valid_stock_basic_info(data: Dict[str, Any]) -> bool:
        """éªŒè¯è‚¡ç¥¨åŸºç¡€ä¿¡æ¯æœ‰æ•ˆæ€§"""
        if not data or not isinstance(data, dict):
            return False

        # æ£€æŸ¥å…³é”®å­—æ®µ
        symbol = data.get("symbol", "")
        name = data.get("name", "")
        market = data.get("market", "")

        return bool(symbol and name and market)


class SyncManager(BaseManager):
    """åŒæ­¥ç®¡ç†å™¨"""

    # ç±»å‹æ³¨è§£å±æ€§ï¼ˆç”±BaseManageråŠ¨æ€æ³¨å…¥ï¼‰
    db_manager: DatabaseManager
    data_source_manager: DataSourceManager
    processing_engine: DataProcessingEngine

    def __init__(
        self,
        db_manager: DatabaseManager,
        data_source_manager: DataSourceManager,
        processing_engine: DataProcessingEngine,
        config: Optional[Config] = None,
        **kwargs,
    ):
        """
        åˆå§‹åŒ–åŒæ­¥ç®¡ç†å™¨

        Args:
            db_manager: æ•°æ®åº“ç®¡ç†å™¨
            data_source_manager: æ•°æ®æºç®¡ç†å™¨
            processing_engine: æ•°æ®å¤„ç†å¼•æ“
            config: é…ç½®å¯¹è±¡
        """
        super().__init__(
            config=config,
            db_manager=db_manager,
            data_source_manager=data_source_manager,
            processing_engine=processing_engine,
            **kwargs,
        )

    def _init_specific_config(self):
        """åˆå§‹åŒ–åŒæ­¥ç®¡ç†å™¨ç‰¹å®šé…ç½®"""
        # åˆå§‹åŒ–åŒæ­¥ç®¡ç†å™¨ç‰¹å®šé…ç½®
        self.enable_auto_gap_fix = self._get_config("auto_gap_fix", True)
        self.enable_validation = self._get_config("enable_validation", True)
        self.max_gap_fix_days = self._get_config("max_gap_fix_days", 7)

    def _init_components(self):
        """åˆå§‹åŒ–å­ç»„ä»¶"""
        # åˆå§‹åŒ–å­ç»„ä»¶
        self.incremental_sync = IncrementalSync(
            self.db_manager,
            self.data_source_manager,
            self.processing_engine,
            self.config,
        )
        self.gap_detector = GapDetector(self.db_manager, self.config)
        self.validator = DataValidator(self.db_manager, self.config)

    def _get_required_attributes(self) -> List[str]:
        """å¿…éœ€å±æ€§åˆ—è¡¨"""
        return [
            "db_manager",
            "data_source_manager",
            "processing_engine",
            "incremental_sync",
            "gap_detector",
            "validator",
        ]

    def _extract_data_safely(self, data: Any) -> Any:
        """
        ç»Ÿä¸€çš„æ•°æ®æ ¼å¼å¤„ç†æ–¹æ³•ï¼Œé¿å…å¤šæ¬¡æ‹†åŒ…

        Args:
            data: å¯èƒ½è¢«åŒ…è£…çš„æ•°æ®

        Returns:
            Any: æ‹†åŒ…åçš„å®é™…æ•°æ®
        """
        # å¦‚æœæ˜¯æ ‡å‡†æˆåŠŸå“åº”æ ¼å¼ {"success": True, "data": ..., "count": ...}
        if isinstance(data, dict) and "success" in data:
            if data.get("success"):
                return data.get("data")
            else:
                # å¤±è´¥å“åº”ï¼Œè¿”å› None æˆ–ç©º
                self.logger.warning(f"æ•°æ®æºè¿”å›å¤±è´¥: {data.get('error', 'æœªçŸ¥é”™è¯¯')}")
                return None

        # å¦‚æœæ˜¯ç®€å•åŒ…è£…æ ¼å¼ {"data": ...} (æ²¡æœ‰successå­—æ®µ)
        elif isinstance(data, dict) and "data" in data and "success" not in data:
            return data["data"]

        # å¦åˆ™ç›´æ¥è¿”å›åŸæ•°æ®
        else:
            return data

    @unified_error_handler(return_dict=True)
    def run_full_sync(
        self,
        target_date: Optional[date] = None,
        symbols: Optional[List[str]] = None,
        frequencies: Optional[List[str]] = None,
    ) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´åŒæ­¥æµç¨‹

        Args:
            target_date: ç›®æ ‡æ—¥æœŸï¼Œé»˜è®¤ä¸ºä»Šå¤©
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œé»˜è®¤ä¸ºæ‰€æœ‰æ´»è·ƒè‚¡ç¥¨
            frequencies: é¢‘ç‡åˆ—è¡¨ï¼Œé»˜è®¤ä¸ºé…ç½®ä¸­çš„é¢‘ç‡

        Returns:
            Dict[str, Any]: å®Œæ•´åŒæ­¥ç»“æœ
        """
        # å¦‚æœæ²¡æœ‰æŒ‡å®šé¢‘ç‡ï¼Œä½¿ç”¨é»˜è®¤é¢‘ç‡
        if frequencies is None:
            frequencies = ["1d"]

        # å¦‚æœæ²¡æœ‰æŒ‡å®šsymbolsï¼Œä½¿ç”¨é»˜è®¤å€¼
        if symbols is None:
            symbols = []

        if not target_date:
            raise ValidationError("ç›®æ ‡æ—¥æœŸä¸èƒ½ä¸ºç©º")

        if target_date is None:
            target_date = datetime.now().date()

        # é™åˆ¶ç›®æ ‡æ—¥æœŸä¸èƒ½è¶…è¿‡ä»Šå¤©ï¼Œä½¿ç”¨åˆç†çš„å†å²æ—¥æœŸ
        today = datetime.now().date()
        if target_date > today:
            # å¦‚æœç›®æ ‡æ—¥æœŸæ˜¯æœªæ¥ï¼Œä½¿ç”¨æœ€è¿‘çš„äº¤æ˜“æ—¥
            target_date = date(2025, 1, 24)  # ä½¿ç”¨å·²çŸ¥æœ‰æ•°æ®çš„æ—¥æœŸ
            self._log_warning("run_full_sync", f"ç›®æ ‡æ—¥æœŸè°ƒæ•´ä¸ºå†å²æ—¥æœŸ: {target_date}")

        try:
            self._log_method_start("run_full_sync", target_date=target_date)
            start_time = datetime.now()

            full_result = {
                "target_date": str(target_date),
                "start_time": start_time.isoformat(),
                "phases": {},
                "summary": {
                    "total_phases": 0,
                    "successful_phases": 0,
                    "failed_phases": 0,
                },
            }

            # é˜¶æ®µ0: æ›´æ–°åŸºç¡€æ•°æ®ï¼ˆäº¤æ˜“æ—¥å†å’Œè‚¡ç¥¨åˆ—è¡¨ï¼‰
            log_phase_start("é˜¶æ®µ0", "æ›´æ–°åŸºç¡€æ•°æ®")

            with create_phase_progress("phase0", 2, "åŸºç¡€æ•°æ®æ›´æ–°", "é¡¹") as pbar:
                try:
                    # æ›´æ–°äº¤æ˜“æ—¥å†
                    update_phase_description("æ›´æ–°äº¤æ˜“æ—¥å†")
                    calendar_result = self._update_trading_calendar(target_date)
                    full_result["phases"]["calendar_update"] = calendar_result
                    full_result["summary"]["total_phases"] += 1
                    # æ›´æ–°è¿›åº¦æ¡
                    if pbar is not None:
                        pbar.update(1)

                    if "error" not in calendar_result:
                        full_result["summary"]["successful_phases"] += 1
                        updated_records = calendar_result.get("updated_records", 0)
                        total_records = calendar_result.get("total_records", 0)
                        years_range = f"{calendar_result.get('start_year')}-{calendar_result.get('end_year')}"
                        log_phase_complete(
                            "äº¤æ˜“æ—¥å†æ›´æ–°",
                            {
                                "å¹´ä»½èŒƒå›´": years_range,
                                "æ–°å¢è®°å½•": f"{updated_records}æ¡",
                                "æ€»è®°å½•": f"{total_records}æ¡",
                            },
                        )
                    else:
                        full_result["summary"]["failed_phases"] += 1
                        log_error(f"äº¤æ˜“æ—¥å†æ›´æ–°å¤±è´¥: {calendar_result['error']}")

                    # æ›´æ–°è‚¡ç¥¨åˆ—è¡¨
                    update_phase_description("æ›´æ–°è‚¡ç¥¨åˆ—è¡¨ï¼ˆå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼‰")
                    stock_list_result = self._update_stock_list()
                    full_result["phases"]["stock_list_update"] = stock_list_result
                    full_result["summary"]["total_phases"] += 1
                    # æ›´æ–°è¿›åº¦æ¡
                    if pbar is not None:
                        pbar.update(1)

                    if "error" not in stock_list_result:
                        full_result["summary"]["successful_phases"] += 1
                        total_stocks = stock_list_result.get("total_stocks", 0)
                        new_stocks = stock_list_result.get("new_stocks", 0)
                        updated_stocks = stock_list_result.get("updated_stocks", 0)
                        log_phase_complete(
                            "è‚¡ç¥¨åˆ—è¡¨æ›´æ–°",
                            {
                                "æ€»è‚¡ç¥¨": f"{total_stocks}åª",
                                "æ–°å¢": f"{new_stocks}åª",
                                "æ›´æ–°": f"{updated_stocks}åª",
                            },
                        )
                    else:
                        full_result["summary"]["failed_phases"] += 1
                        log_error(f"è‚¡ç¥¨åˆ—è¡¨æ›´æ–°å¤±è´¥: {stock_list_result['error']}")

                except Exception as e:
                    log_error(f"åŸºç¡€æ•°æ®æ›´æ–°å¤±è´¥: {e}")
                    full_result["phases"]["base_data_update"] = {"error": str(e)}
                    full_result["summary"]["total_phases"] += 1
                    full_result["summary"]["failed_phases"] += 1

            # å¦‚æœæ²¡æœ‰æŒ‡å®šè‚¡ç¥¨åˆ—è¡¨ï¼Œä»æ•°æ®åº“è·å–æ´»è·ƒè‚¡ç¥¨
            if not symbols:
                symbols = self._get_active_stocks_from_db()
                if not symbols:
                    # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰è‚¡ç¥¨ï¼Œä½¿ç”¨é»˜è®¤è‚¡ç¥¨
                    symbols = ["000001.SZ", "000002.SZ", "600000.SS", "600036.SS"]
                    self.logger.info(f"ä½¿ç”¨é»˜è®¤è‚¡ç¥¨åˆ—è¡¨: {len(symbols)}åªè‚¡ç¥¨")
                else:
                    self.logger.info(f"ä»æ•°æ®åº“è·å–æ´»è·ƒè‚¡ç¥¨: {len(symbols)}åªè‚¡ç¥¨")

            # é˜¶æ®µ1: å¢é‡åŒæ­¥ï¼ˆå¸‚åœºæ•°æ®ï¼‰
            log_phase_start("é˜¶æ®µ1", "å¢é‡åŒæ­¥å¸‚åœºæ•°æ®")

            with create_phase_progress(
                "phase1", len(symbols), "å¢é‡åŒæ­¥", "è‚¡ç¥¨"
            ) as pbar:
                try:
                    # ä¿®æ”¹å¢é‡åŒæ­¥ä»¥æ”¯æŒè¿›åº¦å›è°ƒ
                    sync_result = self.incremental_sync.sync_all_symbols(
                        target_date, symbols, frequencies, progress_bar=pbar
                    )
                    full_result["phases"]["incremental_sync"] = {
                        "status": "completed",
                        "result": sync_result,
                    }
                    full_result["summary"]["successful_phases"] += 1

                    # ä»ç»“æœä¸­æå–ç»Ÿè®¡ä¿¡æ¯
                    success_count = sync_result.get("success_count", len(symbols))
                    error_count = sync_result.get("error_count", 0)
                    log_phase_complete(
                        "å¢é‡åŒæ­¥",
                        {"æˆåŠŸ": f"{success_count}åªè‚¡ç¥¨", "å¤±è´¥": error_count},
                    )

                except Exception as e:
                    log_error(f"å¢é‡åŒæ­¥å¤±è´¥: {e}")
                    full_result["phases"]["incremental_sync"] = {
                        "status": "failed",
                        "error": str(e),
                    }
                    full_result["summary"]["failed_phases"] += 1

            full_result["summary"]["total_phases"] += 1

            # é˜¶æ®µ2: åŒæ­¥æ‰©å±•æ•°æ®
            log_phase_start("é˜¶æ®µ2", "åŒæ­¥æ‰©å±•æ•°æ®")

            # é¢„æ£€æŸ¥æ‰©å±•æ•°æ®åŒæ­¥çš„æ–­ç‚¹ç»­ä¼ çŠ¶æ€
            extended_symbols_to_process = self._get_extended_data_symbols_to_process(
                symbols, target_date
            )

            self.logger.info(
                f"ğŸ“Š æ‰©å±•æ•°æ®åŒæ­¥: æ€»è‚¡ç¥¨ {len(symbols)}åª, éœ€å¤„ç† {len(extended_symbols_to_process)}åª"
            )

            # å¦‚æœæ²¡æœ‰è‚¡ç¥¨éœ€è¦å¤„ç†ï¼Œç›´æ¥è·³è¿‡
            if len(extended_symbols_to_process) == 0:
                self.logger.info("âœ… æ‰€æœ‰è‚¡ç¥¨çš„æ‰©å±•æ•°æ®å·²å®Œæˆï¼Œè·³è¿‡æ‰©å±•æ•°æ®åŒæ­¥")
                full_result["phases"]["extended_data_sync"] = {
                    "status": "skipped",
                    "result": {"message": "æ‰€æœ‰æ•°æ®å·²å®Œæ•´ï¼Œæ— éœ€å¤„ç†"},
                }
                full_result["summary"]["successful_phases"] += 1
                log_phase_complete("æ‰©å±•æ•°æ®åŒæ­¥", {"çŠ¶æ€": "å·²å®Œæˆï¼Œè·³è¿‡"})
            else:
                # ä½¿ç”¨éœ€è¦å¤„ç†çš„è‚¡ç¥¨æ•°é‡ä½œä¸ºè¿›åº¦æ¡åŸºå‡†
                with create_phase_progress(
                    "phase2", len(extended_symbols_to_process), "æ‰©å±•æ•°æ®åŒæ­¥", "è‚¡ç¥¨"
                ) as pbar:
                    try:
                        extended_result = self._sync_extended_data(
                            extended_symbols_to_process,
                            target_date,
                            pbar,  # åªä¼ å…¥éœ€è¦å¤„ç†çš„è‚¡ç¥¨
                        )
                        full_result["phases"]["extended_data_sync"] = {
                            "status": "completed",
                            "result": extended_result,
                        }
                        full_result["summary"]["successful_phases"] += 1

                        log_phase_complete(
                            "æ‰©å±•æ•°æ®åŒæ­¥",
                            {
                                "è´¢åŠ¡æ•°æ®": f"{extended_result.get('financials_count', 0)}æ¡",
                                "ä¼°å€¼æ•°æ®": f"{extended_result.get('valuations_count', 0)}æ¡",
                                "æŠ€æœ¯æŒ‡æ ‡": f"{extended_result.get('indicators_count', 0)}æ¡",
                            },
                        )

                    except Exception as e:
                        log_error(f"æ‰©å±•æ•°æ®åŒæ­¥å¤±è´¥: {e}")
                        full_result["phases"]["extended_data_sync"] = {
                            "status": "failed",
                            "error": str(e),
                        }
                        full_result["summary"]["failed_phases"] += 1

            full_result["summary"]["total_phases"] += 1

            # é˜¶æ®µ3: ç¼ºå£æ£€æµ‹
            log_phase_start("é˜¶æ®µ3", "ç¼ºå£æ£€æµ‹ä¸ä¿®å¤")

            with create_phase_progress(
                "phase2", len(symbols), "ç¼ºå£æ£€æµ‹", "è‚¡ç¥¨"
            ) as pbar:
                try:
                    gap_start_date = target_date - timedelta(days=30)  # æ£€æµ‹æœ€è¿‘30å¤©
                    gap_result = self.gap_detector.detect_all_gaps(
                        gap_start_date, target_date, symbols, frequencies
                    )

                    # æ›´æ–°è¿›åº¦
                    # æ›´æ–°è¿›åº¦
                    if pbar is not None:
                        pbar.update(len(symbols))

                    full_result["phases"]["gap_detection"] = {
                        "status": "completed",
                        "result": gap_result,
                    }
                    full_result["summary"]["successful_phases"] += 1

                    total_gaps = gap_result["summary"]["total_gaps"]

                    # è‡ªåŠ¨ä¿®å¤ç¼ºå£
                    if self.enable_auto_gap_fix and total_gaps > 0:
                        update_phase_description(f"ä¿®å¤{total_gaps}ä¸ªç¼ºå£")
                        fix_result = self._auto_fix_gaps(gap_result)
                        full_result["phases"]["gap_fix"] = {
                            "status": "completed",
                            "result": fix_result,
                        }
                        log_phase_complete(
                            "ç¼ºå£æ£€æµ‹ä¸ä¿®å¤",
                            {"æ£€æµ‹": f"{total_gaps}ä¸ªç¼ºå£", "ä¿®å¤": "å®Œæˆ"},
                        )
                    else:
                        log_phase_complete("ç¼ºå£æ£€æµ‹", {"ç¼ºå£": f"{total_gaps}ä¸ª"})

                except Exception as e:
                    log_error(f"ç¼ºå£æ£€æµ‹å¤±è´¥: {e}")
                    full_result["phases"]["gap_detection"] = {
                        "status": "failed",
                        "error": str(e),
                    }
                    full_result["summary"]["failed_phases"] += 1

            full_result["summary"]["total_phases"] += 1

            # é˜¶æ®µ3: æ•°æ®éªŒè¯
            if self.enable_validation:
                log_phase_start("é˜¶æ®µ3", "æ•°æ®éªŒè¯")

                with create_phase_progress(
                    "phase3", len(symbols), "æ•°æ®éªŒè¯", "è‚¡ç¥¨"
                ) as pbar:
                    try:
                        validation_start_date = target_date - timedelta(
                            days=7
                        )  # éªŒè¯æœ€è¿‘7å¤©
                        validation_result = self.validator.validate_all_data(
                            validation_start_date, target_date, symbols, frequencies
                        )

                        # æ›´æ–°è¿›åº¦
                        if pbar is not None:
                            pbar.update(len(symbols))

                        full_result["phases"]["validation"] = {
                            "status": "completed",
                            "result": validation_result,
                        }
                        full_result["summary"]["successful_phases"] += 1

                        # æå–éªŒè¯ç»Ÿè®¡
                        total_records = validation_result.get("total_records", 0)
                        valid_records = validation_result.get("valid_records", 0)
                        validation_rate = validation_result.get("validation_rate", 0)

                        log_phase_complete(
                            "æ•°æ®éªŒè¯",
                            {
                                "è®°å½•": f"{total_records}æ¡",
                                "æœ‰æ•ˆ": f"{valid_records}æ¡",
                                "éªŒè¯ç‡": f"{validation_rate:.1f}%",
                            },
                        )

                    except Exception as e:
                        log_error(f"æ•°æ®éªŒè¯å¤±è´¥: {e}")
                        full_result["phases"]["validation"] = {
                            "status": "failed",
                            "error": str(e),
                        }
                        full_result["summary"]["failed_phases"] += 1

                full_result["summary"]["total_phases"] += 1

            # å®Œæˆæ—¶é—´
            end_time = datetime.now()
            full_result["end_time"] = end_time.isoformat()
            full_result["duration_seconds"] = (end_time - start_time).total_seconds()

            self._log_performance(
                "run_full_sync",
                full_result["duration_seconds"],
                successful_phases=full_result["summary"]["successful_phases"],
                failed_phases=full_result["summary"]["failed_phases"],
            )

            return full_result

        except Exception as e:
            self._log_error("run_full_sync", e, target_date=target_date)
            raise

    def get_sync_status(self) -> Dict[str, Any]:
        """è·å–åŒæ­¥çŠ¶æ€"""
        try:
            # è·å–æœ€è¿‘çš„åŒæ­¥çŠ¶æ€
            sql = """
            SELECT * FROM sync_status
            ORDER BY last_sync_date DESC
            LIMIT 10
            """
            recent_syncs = self.db_manager.fetchall(sql)

            # è·å–æ•°æ®ç»Ÿè®¡
            stats_sql = """
            SELECT 
                COUNT(*) as total_records,
                COUNT(DISTINCT symbol) as total_symbols,
                COUNT(DISTINCT date) as total_dates,
                MIN(date) as earliest_date,
                MAX(date) as latest_date,
                AVG(quality_score) as avg_quality
            FROM market_data
            """
            stats_result = self.db_manager.fetchone(stats_sql)

            # è·å–ç»„ä»¶çŠ¶æ€
            components_status = {
                "incremental_sync": {
                    "initialized": hasattr(self, "incremental_sync")
                    and self.incremental_sync is not None,
                    "type": "IncrementalSync",
                },
                "gap_detector": {
                    "initialized": hasattr(self, "gap_detector")
                    and self.gap_detector is not None,
                    "type": "GapDetector",
                },
                "validator": {
                    "initialized": hasattr(self, "validator")
                    and self.validator is not None,
                    "type": "DataValidator",
                },
            }

            # è¿”å›æ ‡å‡†æ ¼å¼
            return {
                "success": True,
                "data": {
                    "recent_syncs": [dict(row) for row in recent_syncs],
                    "data_stats": dict(stats_result) if stats_result else {},
                    "components": components_status,
                    "config": {
                        "enable_auto_gap_fix": self.enable_auto_gap_fix,
                        "enable_validation": self.enable_validation,
                        "max_gap_fix_days": self.max_gap_fix_days,
                    },
                },
            }
        except Exception as e:
            self.logger.error(f"è·å–åŒæ­¥çŠ¶æ€å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}

    def _get_active_stocks_from_db(self) -> List[str]:
        """ä»æ•°æ®åº“è·å–æ´»è·ƒè‚¡ç¥¨åˆ—è¡¨"""
        sql = "SELECT symbol FROM stocks WHERE status = 'active' ORDER BY symbol"
        result = self.db_manager.fetchall(sql)
        return [row["symbol"] for row in result] if result else []

    def _get_extended_data_symbols_to_process(
        self, symbols: List[str], target_date: date
    ) -> List[str]:
        """
        è·å–éœ€è¦å¤„ç†æ‰©å±•æ•°æ®çš„è‚¡ç¥¨åˆ—è¡¨ï¼ˆä¿®å¤æ–­ç‚¹ç»­ä¼ ç‰ˆæœ¬ï¼‰
        """
        try:
            self.logger.info("ğŸ“Š æ£€æŸ¥æ‰©å±•æ•°æ®å®Œæ•´æ€§ï¼ˆä¿®å¤æ–­ç‚¹ç»­ä¼ ï¼‰...")

            if not symbols:
                return []

            # æ¸…ç†è¿‡æœŸçš„pendingçŠ¶æ€
            cleanup_count = self.db_manager.execute(
                """
                DELETE FROM extended_sync_status 
                WHERE target_date = ? AND status = 'pending' 
                AND created_at < datetime('now', '-1 day')
                """,
                (str(target_date),),
            )

            # æ ¸å¿ƒä¿®å¤ï¼šåŸºäºå®é™…æ•°æ®å®Œæ•´æ€§åˆ¤æ–­ï¼Œè€Œä¸æ˜¯çŠ¶æ€è¡¨
            report_date = f"{target_date.year}-12-31"
            placeholders = ",".join(["?" for _ in symbols])

            # æŸ¥è¯¢å®é™…æ•°æ®å®Œæ•´æ€§ï¼ŒåŒ…æ‹¬å·²æ ‡è®°å®Œæˆä½†æ•°æ®ç¼ºå¤±çš„æƒ…å†µ
            data_completeness_query = f"""
            WITH symbol_list AS (
                SELECT symbol FROM stocks 
                WHERE symbol IN ({placeholders}) AND status = 'active'
            ),
            financial_data AS (
                SELECT DISTINCT symbol FROM financials 
                WHERE symbol IN ({placeholders}) 
                AND report_date = ?
            ),
            valuation_data AS (
                SELECT DISTINCT symbol FROM valuations 
                WHERE symbol IN ({placeholders})
                AND date = ?
            ),
            indicator_data AS (
                SELECT DISTINCT symbol FROM technical_indicators 
                WHERE symbol IN ({placeholders})
                AND date = ? AND frequency = '1d'
            ),
            status_data AS (
                SELECT DISTINCT symbol, status FROM extended_sync_status
                WHERE symbol IN ({placeholders}) 
                AND target_date = ? AND status = 'completed'
            )
            SELECT 
                sl.symbol,
                CASE WHEN fd.symbol IS NOT NULL THEN 1 ELSE 0 END AS has_financial,
                CASE WHEN vd.symbol IS NOT NULL THEN 1 ELSE 0 END AS has_valuation,
                CASE WHEN id.symbol IS NOT NULL THEN 1 ELSE 0 END AS has_indicators,
                CASE WHEN sd.symbol IS NOT NULL THEN 1 ELSE 0 END AS marked_completed
            FROM symbol_list sl
            LEFT JOIN financial_data fd ON sl.symbol = fd.symbol
            LEFT JOIN valuation_data vd ON sl.symbol = vd.symbol  
            LEFT JOIN indicator_data id ON sl.symbol = id.symbol
            LEFT JOIN status_data sd ON sl.symbol = sd.symbol
            """

            # æ‰§è¡ŒæŸ¥è¯¢
            query_params = (
                tuple(symbols)
                + tuple(symbols)
                + (report_date,)
                + tuple(symbols)
                + (str(target_date),)
                + tuple(symbols)
                + (str(target_date),)
                + tuple(symbols)
                + (str(target_date),)
            )
            results = self.db_manager.fetchall(data_completeness_query, query_params)

            # åˆ†æç»“æœå¹¶ä¿®å¤çŠ¶æ€ä¸ä¸€è‡´
            symbols_needing_processing = []
            inconsistent_symbols = []  # çŠ¶æ€æ ‡è®°å®Œæˆä½†æ•°æ®ç¼ºå¤±
            stats = {
                "total_checked": len(results),
                "has_all": 0,
                "missing_financial": 0,
                "missing_valuation": 0,
                "missing_indicators": 0,
                "needs_processing": 0,
                "status_inconsistent": 0,
            }

            for row in results:
                symbol = row["symbol"]
                has_financial = row["has_financial"]
                has_valuation = row["has_valuation"]
                has_indicators = row["has_indicators"]
                marked_completed = row["marked_completed"]

                # ç»Ÿè®¡
                if has_financial and has_valuation and has_indicators:
                    stats["has_all"] += 1
                if not has_financial:
                    stats["missing_financial"] += 1
                if not has_valuation:
                    stats["missing_valuation"] += 1
                if not has_indicators:
                    stats["missing_indicators"] += 1

                # æ£€æŸ¥çŠ¶æ€ä¸ä¸€è‡´ï¼šæ ‡è®°å®Œæˆä½†æ•°æ®ç¼ºå¤±
                if marked_completed and (not has_financial or not has_valuation):
                    inconsistent_symbols.append(symbol)
                    stats["status_inconsistent"] += 1
                    self.logger.warning(
                        f"çŠ¶æ€ä¸ä¸€è‡´: {symbol} æ ‡è®°å®Œæˆä½†ç¼ºå°‘æ•°æ® (è´¢åŠ¡:{has_financial}, ä¼°å€¼:{has_valuation})"
                    )

                # éœ€è¦å¤„ç†çš„æ¡ä»¶ï¼šä¸»è¦æ•°æ®ä¸å®Œæ•´ï¼ˆæŠ€æœ¯æŒ‡æ ‡æš‚æ—¶å¯é€‰ï¼‰
                if not has_financial or not has_valuation:
                    symbols_needing_processing.append(symbol)
                    stats["needs_processing"] += 1

            # ä¿®å¤çŠ¶æ€ä¸ä¸€è‡´ï¼šæ¸…ç†é”™è¯¯çš„å®ŒæˆçŠ¶æ€
            if inconsistent_symbols:
                placeholders_inconsistent = ",".join(
                    ["?" for _ in inconsistent_symbols]
                )
                self.db_manager.execute(
                    f"""
                    DELETE FROM extended_sync_status 
                    WHERE symbol IN ({placeholders_inconsistent}) 
                    AND target_date = ? AND status = 'completed'
                    """,
                    tuple(inconsistent_symbols) + (str(target_date),),
                )
                self.logger.info(
                    f"ğŸ”§ ä¿®å¤çŠ¶æ€ä¸ä¸€è‡´: æ¸…ç†äº† {len(inconsistent_symbols)} ä¸ªé”™è¯¯çš„å®ŒæˆçŠ¶æ€"
                )

            # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
            self.logger.info(
                f"ğŸ“Š æ•°æ®å®Œæ•´æ€§æ£€æŸ¥: "
                f"æ€»è®¡{stats['total_checked']}, "
                f"å®Œæ•´{stats['has_all']}, "
                f"ç¼ºè´¢åŠ¡{stats['missing_financial']}, "
                f"ç¼ºä¼°å€¼{stats['missing_valuation']}, "
                f"ç¼ºæŒ‡æ ‡{stats['missing_indicators']}, "
                f"éœ€å¤„ç†{stats['needs_processing']}, "
                f"çŠ¶æ€ä¿®å¤{stats['status_inconsistent']}"
            )

            if symbols_needing_processing:
                self.logger.info(
                    f"ğŸ“‹ å®é™…éœ€è¦å¤„ç†æ‰©å±•æ•°æ®: {len(symbols_needing_processing)} åªè‚¡ç¥¨"
                )

                # é™åˆ¶å¤„ç†æ•°é‡ï¼Œä½†è¦è€ƒè™‘å·²å®Œæˆçš„
                max_process = min(len(symbols_needing_processing), 100)  # é™ä½åˆ°100åª
                if len(symbols_needing_processing) > max_process:
                    self.logger.info(f"ğŸ¯ é™åˆ¶å¤„ç†æ•°é‡ä¸º {max_process} åªè‚¡ç¥¨")
                    symbols_needing_processing = symbols_needing_processing[
                        :max_process
                    ]
            else:
                self.logger.info("âœ… æ‰€æœ‰è‚¡ç¥¨çš„æ‰©å±•æ•°æ®å·²å®Œæ•´")

            return symbols_needing_processing

        except Exception as e:
            self.logger.error(f"æ£€æŸ¥æ‰©å±•æ•°æ®å®Œæ•´æ€§å¤±è´¥: {e}")
            raise

    def _update_trading_calendar(self, target_date: date) -> Dict[str, Any]:
        """å¢é‡æ›´æ–°äº¤æ˜“æ—¥å†"""
        self.logger.info(f"ğŸ”„ å¼€å§‹äº¤æ˜“æ—¥å†å¢é‡æ›´æ–°ï¼Œç›®æ ‡æ—¥æœŸ: {target_date}")

        # æ£€æŸ¥ç°æœ‰æ•°æ®èŒƒå›´
        existing_range = self.db_manager.fetchone(
            "SELECT MIN(date) as min_date, MAX(date) as max_date, COUNT(*) as count FROM trading_calendar"
        )

        # è®¡ç®—éœ€è¦æ›´æ–°çš„å¹´ä»½
        needed_start_year = target_date.year - 1
        needed_end_year = target_date.year + 1
        years_to_update = list(range(needed_start_year, needed_end_year + 1))

        if existing_range and existing_range["count"] > 0:
            from datetime import datetime

            existing_min = datetime.strptime(
                existing_range["min_date"], "%Y-%m-%d"
            ).date()
            existing_max = datetime.strptime(
                existing_range["max_date"], "%Y-%m-%d"
            ).date()

            # åªæ·»åŠ ç¼ºå¤±çš„å¹´ä»½
            years_to_update = [
                y
                for y in years_to_update
                if y < existing_min.year or y > existing_max.year
            ]

            if not years_to_update:
                return {
                    "status": "skipped",
                    "message": "äº¤æ˜“æ—¥å†å·²æ˜¯æœ€æ–°",
                    "start_year": existing_min.year,
                    "end_year": existing_max.year,
                    "updated_records": 0,
                    "total_records": existing_range["count"],
                }

        self.logger.info(f"éœ€è¦æ›´æ–°å¹´ä»½: {years_to_update}")
        total_inserted = 0

        # è·å–å¹¶æ’å…¥æ•°æ®
        for year in years_to_update:
            start_date = f"{year}-01-01"
            end_date = f"{year}-12-31"

            calendar_data = self.data_source_manager.get_trade_calendar(
                start_date, end_date
            )

            if isinstance(calendar_data, dict) and "data" in calendar_data:
                calendar_data = calendar_data["data"]

            if not calendar_data or not isinstance(calendar_data, list):
                continue

            # æ’å…¥æ•°æ®
            for record in calendar_data:
                self.db_manager.execute(
                    "INSERT OR REPLACE INTO trading_calendar (date, market, is_trading) VALUES (?, ?, ?)",
                    (
                        record.get("trade_date", record.get("date")),
                        "CN",
                        record.get("is_trading", 1),
                    ),
                )
                total_inserted += 1

        # éªŒè¯ç»“æœ
        final_range = self.db_manager.fetchone(
            "SELECT MIN(date) as min_date, MAX(date) as max_date, COUNT(*) as count FROM trading_calendar"
        )

        return {
            "status": "completed",
            "start_year": (
                final_range["min_date"][:4] if final_range else needed_start_year
            ),
            "end_year": final_range["max_date"][:4] if final_range else needed_end_year,
            "updated_records": total_inserted,
            "total_records": final_range["count"] if final_range else 0,
        }

    def _update_stock_list(self) -> Dict[str, Any]:
        """å¢é‡æ›´æ–°è‚¡ç¥¨åˆ—è¡¨ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
        self.logger.info("ğŸ”„ å¼€å§‹è‚¡ç¥¨åˆ—è¡¨å¢é‡æ›´æ–°ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰...")

        try:
            # å¢é‡ç­–ç•¥ï¼šæ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
            last_update = self.db_manager.fetchone(
                "SELECT MAX(updated_at) as last_update FROM stocks WHERE status = 'active'"
            )

            # å¦‚æœä»Šå¤©å·²ç»æ›´æ–°è¿‡ï¼Œä¸”è‚¡ç¥¨æ•°é‡åˆç†ï¼Œè·³è¿‡æ›´æ–°
            from datetime import datetime

            today = datetime.now().date()

            if last_update and last_update["last_update"]:
                last_update_date = datetime.fromisoformat(
                    last_update["last_update"]
                ).date()
                stock_count = self.db_manager.fetchone(
                    "SELECT COUNT(*) as count FROM stocks WHERE status = 'active'"
                )

                # å¦‚æœä»Šå¤©å·²æ›´æ–°è¿‡ä¸”è‚¡ç¥¨æ•°é‡ > 3000ï¼Œè·³è¿‡
                if (
                    last_update_date >= today
                    and stock_count
                    and stock_count["count"] > 3000
                ):
                    self.logger.info(
                        f"âœ… è‚¡ç¥¨åˆ—è¡¨ä»Šæ—¥å·²æ›´æ–°ï¼Œå…± {stock_count['count']} åªè‚¡ç¥¨ï¼Œè·³è¿‡æ›´æ–°"
                    )
                    return {
                        "status": "skipped",
                        "message": "ä»Šæ—¥å·²æ›´æ–°ï¼Œè·³è¿‡",
                        "total_stocks": stock_count["count"],
                        "new_stocks": 0,
                        "updated_stocks": 0,
                        "failed_stocks": 0,
                    }

            # è·å–è‚¡ç¥¨ä¿¡æ¯
            stock_info = self.data_source_manager.get_stock_info()
            self.logger.info(f"åŸå§‹è‚¡ç¥¨ä¿¡æ¯ç±»å‹: {type(stock_info)}")

            # è¯Šæ–­æ•°æ®ç»“æ„
            if isinstance(stock_info, dict):
                self.logger.info(f"å­—å…¸é”®: {list(stock_info.keys())}")
                if "data" in stock_info:
                    self.logger.info(f"dataå­—æ®µç±»å‹: {type(stock_info['data'])}")
                if "success" in stock_info:
                    self.logger.info(f"successå­—æ®µå€¼: {stock_info['success']}")

            # ä¿®å¤è§£åŒ…åµŒå¥—æ•°æ®çš„é€»è¾‘
            if isinstance(stock_info, dict):
                self.logger.info(f"æ£€æµ‹åˆ°å­—å…¸æ ¼å¼ï¼Œé”®: {list(stock_info.keys())}")

                if "success" in stock_info and "data" in stock_info:
                    if stock_info["success"]:
                        stock_info = stock_info["data"]
                        self.logger.info(
                            f"æˆåŠŸè§£åŒ…AkShareæ ¼å¼ï¼Œæ•°æ®ç±»å‹: {type(stock_info)}"
                        )
                    else:
                        error_msg = stock_info.get("error", "æœªçŸ¥é”™è¯¯")
                        self.logger.error(f"æ•°æ®æºè¿”å›å¤±è´¥: {error_msg}")
                        return {
                            "status": "failed",
                            "error": f"æ•°æ®æºè¿”å›å¤±è´¥: {error_msg}",
                            "total_stocks": 0,
                            "new_stocks": 0,
                            "updated_stocks": 0,
                        }
                # ç»Ÿä¸€æ•°æ®æ ¼å¼å¤„ç† - é¿å…å¤šæ¬¡æ‹†åŒ…
                stock_info = self._extract_data_safely(stock_info)

                if not stock_info:
                    self.logger.error("è§£åŒ…åæ•°æ®ä¸ºç©º")
                    return {
                        "status": "failed",
                        "error": "è‚¡ç¥¨æ•°æ®æ ¼å¼é”™è¯¯: è§£åŒ…åæ•°æ®ä¸ºç©º",
                        "total_stocks": 0,
                        "new_stocks": 0,
                        "updated_stocks": 0,
                    }

            # æœ€ç»ˆéªŒè¯æ•°æ®æ ¼å¼
            if stock_info is None:
                self.logger.warning("è§£åŒ…åæ•°æ®ä¸ºç©º")
                return {
                    "status": "failed",
                    "error": "è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥ï¼šè§£åŒ…åæ•°æ®ä¸ºç©º",
                    "total_stocks": 0,
                    "new_stocks": 0,
                    "updated_stocks": 0,
                }

            # è®°å½•æœ€ç»ˆçš„æ•°æ®ç±»å‹å’Œé•¿åº¦
            if hasattr(stock_info, "__len__"):
                self.logger.info(
                    f"æœ€ç»ˆæ•°æ®æ ¼å¼: {type(stock_info)}, é•¿åº¦: {len(stock_info)}"
                )
            else:
                self.logger.warning(f"æœ€ç»ˆæ•°æ®ä¸æ˜¯å¯è¿­ä»£å¯¹è±¡: {type(stock_info)}")

            # è½¬æ¢DataFrameä¸ºåˆ—è¡¨æ ¼å¼
            if hasattr(stock_info, "iterrows"):
                stock_list = []
                for _, row in stock_info.iterrows():
                    try:
                        # å®‰å…¨åœ°æå–æ•°æ®ï¼Œå¤„ç†å¯èƒ½çš„ç©ºå€¼æˆ–å¼‚å¸¸å€¼
                        code = str(row.get("ä»£ç ", "")).strip()
                        name = str(row.get("åç§°", "")).strip()

                        # è·³è¿‡æ— æ•ˆæ•°æ®
                        if not code or not name or code == "nan" or name == "nan":
                            continue

                        stock_data = {
                            "symbol": code,
                            "name": name,
                            "market": self._determine_market(code),
                        }
                        stock_list.append(stock_data)
                    except Exception as e:
                        self.logger.debug(f"è·³è¿‡æ— æ•ˆè¡Œæ•°æ®: {e}")
                        continue

                stock_info = stock_list
                self.logger.info(f"DataFrameè½¬æ¢å®Œæˆï¼Œå…± {len(stock_list)} åªæœ‰æ•ˆè‚¡ç¥¨")
            elif isinstance(stock_info, list):
                # å¦‚æœå·²ç»æ˜¯åˆ—è¡¨ï¼Œæ£€æŸ¥æ ¼å¼
                self.logger.info(f"æ•°æ®å·²æ˜¯åˆ—è¡¨æ ¼å¼ï¼Œå…± {len(stock_info)} é¡¹")
            else:
                self.logger.warning(f"æœªçŸ¥çš„stock_infoæ•°æ®æ ¼å¼: {type(stock_info)}")

            if not stock_info or not hasattr(stock_info, "__len__"):
                self.logger.warning("è‚¡ç¥¨åˆ—è¡¨æ•°æ®æ ¼å¼ä¸æ­£ç¡®")
                return {
                    "status": "failed",
                    "error": "è‚¡ç¥¨åˆ—è¡¨æ•°æ®æ ¼å¼ä¸æ­£ç¡®",
                    "total_stocks": 0,
                    "new_stocks": 0,
                    "updated_stocks": 0,
                }

            # æ€§èƒ½ä¼˜åŒ–ï¼šé™åˆ¶å¤„ç†æ•°é‡ï¼Œä¼˜å…ˆå¤„ç†ä¸»æ¿è‚¡ç¥¨
            if len(stock_info) > 1000:
                # æŒ‰é‡è¦æ€§æ’åºï¼šä¸»æ¿è‚¡ç¥¨ä¼˜å…ˆ
                def get_priority(stock):
                    symbol = stock.get("symbol", "")
                    if symbol.startswith("60"):  # æ²ªå¸‚ä¸»æ¿
                        return 1
                    elif symbol.startswith("00"):  # æ·±å¸‚ä¸»æ¿
                        return 2
                    elif symbol.startswith("30"):  # åˆ›ä¸šæ¿
                        return 3
                    else:
                        return 4

                stock_info.sort(key=get_priority)
                # åªå¤„ç†å‰800åªé‡è¦è‚¡ç¥¨ï¼Œå‡å°‘APIè°ƒç”¨
                stock_info = stock_info[:800]
                self.logger.info(f"ğŸ¯ ä¼˜åŒ–å¤„ç†ï¼šåªæ›´æ–°å‰ {len(stock_info)} åªé‡è¦è‚¡ç¥¨")

            # æ‰¹é‡å¤„ç†è‚¡ç¥¨æ•°æ® - æ€§èƒ½ä¼˜åŒ–
            new_stocks = 0
            updated_stocks = 0
            failed_stocks = 0

            # é¢„å¤„ç†æ‰€æœ‰è‚¡ç¥¨æ•°æ® - ä¿®å¤ç‰ˆæœ¬
            processed_stocks = []

            # ç¡®ä¿stock_infoæ˜¯åˆ—è¡¨æ ¼å¼
            if not isinstance(stock_info, (list, tuple)) and not hasattr(
                stock_info, "__iter__"
            ):
                self.logger.error(f"stock_infoä¸æ˜¯å¯è¿­ä»£å¯¹è±¡: {type(stock_info)}")
                return {
                    "status": "failed",
                    "error": f"è‚¡ç¥¨æ•°æ®ä¸æ˜¯å¯è¿­ä»£æ ¼å¼: {type(stock_info)}",
                    "total_stocks": 0,
                    "new_stocks": 0,
                    "updated_stocks": 0,
                    "failed_stocks": 0,
                }

            self.logger.info(
                f"å¼€å§‹é¢„å¤„ç†è‚¡ç¥¨æ•°æ®ï¼Œæ•°æ®ç±»å‹: {type(stock_info)}, é•¿åº¦: {len(stock_info) if hasattr(stock_info, '__len__') else 'æœªçŸ¥'}"
            )

            for i, stock_data in enumerate(stock_info):
                try:
                    # æ£€æŸ¥æ•°æ®ç±»å‹
                    if not isinstance(stock_data, dict):
                        if i < 5:  # åªè®°å½•å‰5ä¸ªé”™è¯¯
                            self.logger.warning(
                                f"ç¬¬{i}ä¸ªè‚¡ç¥¨æ•°æ®ä¸æ˜¯å­—å…¸: ç±»å‹={type(stock_data)}, å†…å®¹={stock_data}"
                            )
                        failed_stocks += 1
                        continue

                    symbol = stock_data.get("symbol", "")
                    name = stock_data.get("name", "")
                    market = stock_data.get("market", "")

                    if not symbol or not name:
                        continue

                    # æ·»åŠ å¸‚åœºåç¼€
                    if "." not in symbol:
                        if symbol.startswith("0") or symbol.startswith("3"):
                            symbol = f"{symbol}.SZ"
                        elif symbol.startswith("6") or symbol.startswith("9"):
                            symbol = f"{symbol}.SS"

                    processed_stocks.append(
                        {"symbol": symbol, "name": name, "market": market}
                    )

                except Exception as e:
                    if failed_stocks < 5:  # åªè®°å½•å‰5ä¸ªé”™è¯¯ï¼Œé¿å…æ—¥å¿—è¿‡å¤š
                        self.logger.error(f"é¢„å¤„ç†ç¬¬{i}ä¸ªè‚¡ç¥¨æ•°æ®å¤±è´¥: {e}")
                    failed_stocks += 1

            if not processed_stocks:
                self.logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„è‚¡ç¥¨æ•°æ®éœ€è¦å¤„ç†")
                return {
                    "status": "completed",
                    "total_stocks": 0,
                    "new_stocks": 0,
                    "updated_stocks": 0,
                    "failed_stocks": failed_stocks,
                }

            # æ‰¹é‡æ£€æŸ¥å·²å­˜åœ¨çš„è‚¡ç¥¨
            symbol_list = [stock["symbol"] for stock in processed_stocks]
            placeholders = ",".join(["?" for _ in symbol_list])
            existing_symbols = set()

            try:
                existing_result = self.db_manager.fetchall(
                    f"SELECT symbol FROM stocks WHERE symbol IN ({placeholders})",
                    tuple(symbol_list),
                )
                existing_symbols = {row["symbol"] for row in existing_result}
                self.logger.debug(f"æ•°æ®åº“ä¸­å·²å­˜åœ¨ {len(existing_symbols)} åªè‚¡ç¥¨")
            except Exception as e:
                self.logger.warning(f"æ‰¹é‡æŸ¥è¯¢å·²å­˜åœ¨è‚¡ç¥¨å¤±è´¥: {e}")
                # å›é€€åˆ°é€ä¸€å¤„ç†
                existing_symbols = set()

            # åˆ†ç¦»æ–°è‚¡ç¥¨å’Œéœ€è¦æ›´æ–°çš„è‚¡ç¥¨
            new_stock_batch = []
            update_stock_batch = []

            for stock in processed_stocks:
                if stock["symbol"] in existing_symbols:
                    update_stock_batch.append((stock["name"], stock["symbol"]))
                else:
                    new_stock_batch.append(
                        (
                            stock["symbol"],
                            stock["name"],
                            stock["market"],
                            stock["market"],  # exchange å­—æ®µ
                            "active",
                        )
                    )

            # æ‰¹é‡æ›´æ–°å·²å­˜åœ¨çš„è‚¡ç¥¨
            if update_stock_batch:
                try:
                    self.db_manager.executemany(
                        "UPDATE stocks SET name = ?, updated_at = datetime('now') WHERE symbol = ?",
                        update_stock_batch,
                    )
                    updated_stocks = len(update_stock_batch)
                    self.logger.debug(f"æ‰¹é‡æ›´æ–° {updated_stocks} åªè‚¡ç¥¨")
                except Exception as e:
                    self.logger.warning(f"æ‰¹é‡æ›´æ–°è‚¡ç¥¨å¤±è´¥: {e}")
                    # é€ä¸€æ›´æ–°
                    for name, symbol in update_stock_batch:
                        try:
                            self.db_manager.execute(
                                "UPDATE stocks SET name = ?, updated_at = datetime('now') WHERE symbol = ?",
                                (name, symbol),
                            )
                            updated_stocks += 1
                        except Exception as e2:
                            self.logger.warning(f"æ›´æ–°è‚¡ç¥¨ {symbol} å¤±è´¥: {e2}")
                            failed_stocks += 1

            # æ‰¹é‡æ’å…¥æ–°è‚¡ç¥¨
            if new_stock_batch:
                try:
                    self.db_manager.executemany(
                        """
                        INSERT INTO stocks (symbol, name, market, exchange, status, created_at, updated_at) 
                        VALUES (?, ?, ?, ?, ?, datetime('now'), datetime('now'))
                        """,
                        new_stock_batch,
                    )
                    new_stocks = len(new_stock_batch)
                    self.logger.debug(f"æ‰¹é‡æ’å…¥ {new_stocks} åªæ–°è‚¡ç¥¨")

                    # å¼‚æ­¥è·å–è¯¦ç»†ä¿¡æ¯ï¼ˆé¿å…é˜»å¡ä¸»æµç¨‹ï¼‰
                    # æ³¨æ„ï¼šç”±äºè¿œç¨‹APIä¸èƒ½å¹¶å‘ï¼Œè¿™é‡Œåªæ˜¯æ ‡è®°éœ€è¦åç»­å¤„ç†
                    for symbol, _, _, _, _ in new_stock_batch[
                        :10
                    ]:  # é™åˆ¶æ•°é‡ï¼Œé¿å…è¿‡åº¦å¤„ç†
                        try:
                            self._fetch_detailed_stock_info(symbol)
                        except Exception as e:
                            self.logger.debug(f"è·å– {symbol} è¯¦ç»†ä¿¡æ¯å¤±è´¥: {e}")

                except Exception as e:
                    self.logger.warning(f"æ‰¹é‡æ’å…¥æ–°è‚¡ç¥¨å¤±è´¥: {e}")
                    # å›é€€åˆ°é€ä¸€æ’å…¥
                    for stock_data in new_stock_batch:
                        try:
                            self.db_manager.execute(
                                """
                                INSERT INTO stocks (symbol, name, market, exchange, status, created_at, updated_at) 
                                VALUES (?, ?, ?, ?, ?, datetime('now'), datetime('now'))
                                """,
                                stock_data,
                            )
                            new_stocks += 1
                        except Exception as e2:
                            self.logger.warning(f"æ’å…¥è‚¡ç¥¨ {stock_data[0]} å¤±è´¥: {e2}")
                            failed_stocks += 1

            total_processed = new_stocks + updated_stocks

            self.logger.info(
                f"è‚¡ç¥¨åˆ—è¡¨æ›´æ–°å®Œæˆ: æ–°å¢ {new_stocks}åª, æ›´æ–° {updated_stocks}åª, å¤±è´¥ {failed_stocks}åª"
            )

            return {
                "status": "completed",
                "total_stocks": total_processed,
                "new_stocks": new_stocks,
                "updated_stocks": updated_stocks,
                "failed_stocks": failed_stocks,
            }

        except Exception as e:
            self.logger.error(f"æ›´æ–°è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
            return {
                "status": "failed",
                "error": str(e),
                "total_stocks": 0,
                "new_stocks": 0,
                "updated_stocks": 0,
            }

    def _determine_market(self, symbol: str) -> str:
        """ç¡®å®šè‚¡ç¥¨å¸‚åœº"""
        if symbol.startswith("0") or symbol.startswith("3"):
            return "SZ"
        elif symbol.startswith("6") or symbol.startswith("9"):
            return "SS"
        elif symbol.startswith("8"):
            return "BJ"  # åŒ—äº¤æ‰€
        else:
            return "SZ"  # é»˜è®¤æ·±åœ³

    def _fetch_detailed_stock_info(self, symbol: str):
        """è·å–è‚¡ç¥¨è¯¦ç»†ä¿¡æ¯ï¼ˆè‚¡æœ¬ã€ä¸Šå¸‚æ—¥æœŸç­‰ï¼‰"""
        try:
            # è·å–è‚¡ç¥¨è¯¦ç»†ä¿¡æ¯
            detail_info = self.data_source_manager.get_stock_info(symbol)

            if isinstance(detail_info, dict) and "data" in detail_info:
                detail_info = detail_info["data"]

            if detail_info is None or (
                hasattr(detail_info, "empty") and detail_info.empty
            ):
                return

            # è§£æè¯¦ç»†ä¿¡æ¯
            if hasattr(detail_info, "iloc") and len(detail_info) > 0:
                row = detail_info.iloc[0]

                # æå–æœ‰ç”¨ä¿¡æ¯
                total_shares = self._safe_extract_number(row.get("æ€»è‚¡æœ¬", 0))
                float_shares = self._safe_extract_number(row.get("æµé€šè‚¡", 0))
                list_date = self._safe_extract_date(row.get("ä¸Šå¸‚æ—¥æœŸ", ""))
                industry = str(row.get("è¡Œä¸š", ""))

                # æ›´æ–°è‚¡ç¥¨è¯¦ç»†ä¿¡æ¯
                if total_shares or float_shares or list_date or industry:
                    self.db_manager.execute(
                        """
                        UPDATE stocks 
                        SET total_shares = ?, float_shares = ?, list_date = ?, industry_l1 = ?
                        WHERE symbol = ?
                        """,
                        (total_shares, float_shares, list_date, industry, symbol),
                    )
                    self.logger.debug(f"æ›´æ–°è‚¡ç¥¨è¯¦ç»†ä¿¡æ¯: {symbol}")

        except Exception as e:
            self.logger.debug(f"è·å– {symbol} è¯¦ç»†ä¿¡æ¯å¤±è´¥: {e}")

    def _safe_extract_number(self, value, default=None):
        """å®‰å…¨æå–æ•°å­—"""
        try:
            if value is None or value == "" or str(value).lower() == "nan":
                return default
            # ç§»é™¤å¯èƒ½çš„å•ä½ï¼ˆä¸‡ã€äº¿ç­‰ï¼‰
            str_value = str(value).replace(",", "").replace("ä¸‡", "").replace("äº¿", "")
            if "ä¸‡" in str(value):
                return float(str_value) * 10000
            elif "äº¿" in str(value):
                return float(str_value) * 100000000
            else:
                return float(str_value)
        except (ValueError, TypeError):
            return default

    def _safe_extract_date(self, value, default=None):
        """å®‰å…¨æå–æ—¥æœŸ"""
        try:
            if value is None or value == "" or str(value).lower() == "nan":
                return default
            # å°è¯•è§£ææ—¥æœŸæ ¼å¼
            import re

            str_value = str(value)
            # åŒ¹é… YYYY-MM-DD æ ¼å¼
            if re.match(r"\d{4}-\d{2}-\d{2}", str_value):
                return str_value[:10]
            # åŒ¹é… YYYYMMDD æ ¼å¼
            elif re.match(r"\d{8}", str_value):
                return f"{str_value[:4]}-{str_value[4:6]}-{str_value[6:8]}"
            else:
                return default
        except Exception:
            return default

    def _sync_extended_data(
        self, symbols: List[str], target_date: date, progress_bar=None
    ) -> Dict[str, Any]:
        """å¢é‡åŒæ­¥æ‰©å±•æ•°æ®ï¼ˆè´¢åŠ¡æ•°æ®ã€ä¼°å€¼æ•°æ®ç­‰ï¼‰"""
        import uuid

        session_id = str(uuid.uuid4())
        self.logger.info(f"ğŸ”„ å¼€å§‹æ‰©å±•æ•°æ®åŒæ­¥: {len(symbols)}åªè‚¡ç¥¨")

        result = {
            "financials_count": 0,
            "valuations_count": 0,
            "indicators_count": 0,
            "processed_symbols": 0,
            "failed_symbols": 0,
            "session_id": session_id,
        }

        # ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„symbolså‚æ•°ï¼Œå› ä¸ºå·²ç»ç»è¿‡_get_extended_data_symbols_to_processè¿‡æ»¤
        self.logger.info(f"ğŸ“Š å¼€å§‹å¤„ç†: {len(symbols)}åªè‚¡ç¥¨")

        if not symbols:
            self.logger.info("âœ… æ²¡æœ‰è‚¡ç¥¨éœ€è¦å¤„ç†")
            if progress_bar:
                progress_bar.update(0)
            return result

        # å¤„ç†æ¯åªè‚¡ç¥¨
        for i, symbol in enumerate(symbols):
            self.logger.debug(f"å¤„ç† {symbol} ({i+1}/{len(symbols)})")

            # æ£€æŸ¥æ˜¯å¦å·²ç»å¤„ç†è¿‡è¿™åªè‚¡ç¥¨
            existing_status = self.db_manager.fetchone(
                "SELECT status FROM extended_sync_status WHERE symbol = ? AND target_date = ? AND session_id = ?",
                (symbol, str(target_date), session_id),
            )

            if existing_status and existing_status["status"] == "completed":
                self.logger.debug(f"è·³è¿‡å·²å®Œæˆçš„è‚¡ç¥¨: {symbol}")
                result["processed_symbols"] += 1
                if progress_bar:
                    progress_bar.update(1)
                continue

            # æ ‡è®°å¼€å§‹å¤„ç†
            self.db_manager.execute(
                "INSERT OR REPLACE INTO extended_sync_status (symbol, sync_type, target_date, status, session_id, created_at, updated_at) VALUES (?, ?, ?, ?, ?, datetime('now'), datetime('now'))",
                (symbol, "processing", str(target_date), "processing", session_id),
            )

            # æ•°æ®è·å–æˆåŠŸæ ‡å¿—
            financial_success = False
            valuation_success = False

            # å¤„ç†è´¢åŠ¡æ•°æ® - ä½¿ç”¨æœ€è¿‘ä¸€å¹´çš„å¹´æŠ¥æ•°æ®
            report_year = target_date.year - 1  # ä½¿ç”¨å»å¹´å¹´æŠ¥
            report_date_str = f"{report_year}-12-31"

            # éªŒè¯æŠ¥å‘ŠæœŸæœ‰æ•ˆæ€§
            if not DataQualityValidator.is_valid_report_date(report_date_str, symbol):
                self.logger.warning(f"è·³è¿‡æ— æ•ˆæŠ¥å‘ŠæœŸ: {symbol} {report_date_str}")
            else:
                try:
                    financial_data = self.data_source_manager.get_fundamentals(
                        symbol, report_date_str, "Q4"
                    )

                    # æ ‡å‡†æ•°æ®æºå“åº”æ ¼å¼è§£åŒ…
                    # ç»Ÿä¸€æ•°æ®æ ¼å¼å¤„ç† - é¿å…å¤šæ¬¡æ‹†åŒ…
                    financial_data = self._extract_data_safely(financial_data)

                    # éªŒè¯è´¢åŠ¡æ•°æ®æœ‰æ•ˆæ€§
                    if financial_data and DataQualityValidator.is_valid_financial_data(
                        financial_data
                    ):
                        self.db_manager.execute(
                            "INSERT OR REPLACE INTO financials (symbol, report_date, report_type, revenue, net_profit, total_assets, source, created_at) VALUES (?, ?, ?, ?, ?, ?, ?, datetime('now'))",
                            (
                                symbol,
                                report_date_str,
                                "Q4",
                                financial_data.get("revenue", 0),
                                financial_data.get("net_profit", 0),
                                financial_data.get("total_assets", 0),
                                "akshare",
                            ),
                        )
                        result["financials_count"] += 1
                        financial_success = True
                        self.logger.debug(f"è´¢åŠ¡æ•°æ®æ’å…¥æˆåŠŸ: {symbol}")
                    else:
                        self.logger.debug(f"è´¢åŠ¡æ•°æ®æ— æ•ˆï¼Œè·³è¿‡: {symbol}")

                except Exception as e:
                    self.logger.warning(f"è·å–è´¢åŠ¡æ•°æ®å¤±è´¥: {symbol} - {e}")

            # å¤„ç†ä¼°å€¼æ•°æ®
            try:
                valuation_data = self.data_source_manager.get_valuation_data(
                    symbol, str(target_date)
                )

                # æ ‡å‡†æ•°æ®æºå“åº”æ ¼å¼è§£åŒ…
                # ç»Ÿä¸€æ•°æ®æ ¼å¼å¤„ç† - é¿å…å¤šæ¬¡æ‹†åŒ…
                valuation_data = self._extract_data_safely(valuation_data)

                # éªŒè¯ä¼°å€¼æ•°æ®æœ‰æ•ˆæ€§
                if valuation_data and DataQualityValidator.is_valid_valuation_data(
                    valuation_data
                ):
                    self.db_manager.execute(
                        "INSERT OR REPLACE INTO valuations (symbol, date, pe_ratio, pb_ratio, market_cap, source, created_at) VALUES (?, ?, ?, ?, ?, ?, datetime('now'))",
                        (
                            symbol,
                            str(target_date),
                            valuation_data.get("pe_ratio", None),
                            valuation_data.get("pb_ratio", None),
                            valuation_data.get("market_cap", None),
                            "akshare",
                        ),
                    )
                    result["valuations_count"] += 1
                    valuation_success = True
                    self.logger.debug(f"ä¼°å€¼æ•°æ®æ’å…¥æˆåŠŸ: {symbol}")
                else:
                    self.logger.debug(f"ä¼°å€¼æ•°æ®æ— æ•ˆï¼Œè·³è¿‡: {symbol}")

            except Exception as e:
                self.logger.warning(f"è·å–ä¼°å€¼æ•°æ®å¤±è´¥: {symbol} - {e}")

            # å¤„ç†æŠ€æœ¯æŒ‡æ ‡ - åªæœ‰å½“æœ‰å¸‚åœºæ•°æ®æ—¶æ‰è®¡ç®—
            indicators_success = False
            try:
                # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„å¸‚åœºæ•°æ®æ¥è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
                market_data_count = self.db_manager.fetchone(
                    "SELECT COUNT(*) as count FROM market_data WHERE symbol = ? AND date <= ? ORDER BY date DESC LIMIT 20",
                    (symbol, str(target_date)),
                )

                if (
                    market_data_count and market_data_count["count"] >= 10
                ):  # è‡³å°‘éœ€è¦10å¤©æ•°æ®
                    # è¿™é‡Œåº”è¯¥è°ƒç”¨çœŸæ­£çš„æŠ€æœ¯æŒ‡æ ‡è®¡ç®—ï¼Œæš‚æ—¶è·³è¿‡è™šå‡æ•°æ®æ’å…¥
                    self.logger.debug(f"æŠ€æœ¯æŒ‡æ ‡è®¡ç®—éœ€è¦å®ç°ï¼Œè·³è¿‡: {symbol}")
                    indicators_success = True  # æš‚æ—¶æ ‡è®°ä¸ºæˆåŠŸï¼Œå› ä¸ºåŠŸèƒ½æœªå®ç°
                else:
                    self.logger.debug(f"å¸‚åœºæ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—æŠ€æœ¯æŒ‡æ ‡: {symbol}")
                    indicators_success = True  # æ•°æ®ä¸è¶³æ—¶ä¹Ÿç®—æ­£å¸¸æƒ…å†µ

            except Exception as e:
                self.logger.warning(f"æŠ€æœ¯æŒ‡æ ‡å¤„ç†å¤±è´¥: {symbol} - {e}")

            # æ ¹æ®æ•°æ®è·å–ç»“æœå†³å®šæœ€ç»ˆçŠ¶æ€
            # è‡³å°‘è¦æœ‰è´¢åŠ¡æ•°æ®æˆ–ä¼°å€¼æ•°æ®ä¹‹ä¸€æˆåŠŸï¼Œæ‰æ ‡è®°ä¸ºå®Œæˆ
            if financial_success or valuation_success:
                final_status = "completed"
                self.logger.debug(
                    f"æ•°æ®è·å–æˆåŠŸ: {symbol} (è´¢åŠ¡:{financial_success}, ä¼°å€¼:{valuation_success})"
                )
            else:
                final_status = "failed"
                result["failed_symbols"] += 1
                self.logger.warning(f"æ•°æ®è·å–å…¨éƒ¨å¤±è´¥: {symbol}")

            # æ›´æ–°æœ€ç»ˆçŠ¶æ€
            self.db_manager.execute(
                "UPDATE extended_sync_status SET status = ?, updated_at = datetime('now') WHERE symbol = ? AND target_date = ? AND session_id = ?",
                (final_status, symbol, str(target_date), session_id),
            )

            result["processed_symbols"] += 1
            if progress_bar:
                progress_bar.update(1)

        return result

    def _auto_fix_gaps(self, gap_result: Dict[str, Any]) -> Dict[str, Any]:
        """è‡ªåŠ¨ä¿®å¤ç¼ºå£"""
        self.logger.info("å¼€å§‹è‡ªåŠ¨ä¿®å¤ç¼ºå£")

        fix_result = {
            "total_gaps": gap_result["summary"]["total_gaps"],
            "attempted_fixes": 0,
            "successful_fixes": 0,
            "failed_fixes": 0,
            "skipped_fixes": 0,  # æ–°å¢ï¼šè·³è¿‡çš„ä¿®å¤
        }

        # å¤„ç†ç¼ºå£æ•°æ®ç»“æ„ - é€‚é…æ–°çš„æ•°æ®æ ¼å¼
        all_gaps = []
        for freq_data in gap_result.get("gaps_by_frequency", {}).values():
            all_gaps.extend(freq_data.get("gaps", []))

        if not all_gaps:
            self.logger.info("æ²¡æœ‰å‘ç°ç¼ºå£ï¼Œæ— éœ€ä¿®å¤")
            return fix_result

        # é™åˆ¶ä¿®å¤æ•°é‡ï¼Œä¼˜å…ˆä¿®å¤é‡è¦è‚¡ç¥¨çš„ç¼ºå£
        max_fixes = 10
        fixes_attempted = 0

        for gap in all_gaps:
            if fixes_attempted >= max_fixes:
                break

            symbol = gap.get("symbol")
            gap_start = gap.get("start_date")
            gap_end = gap.get("end_date")
            frequency = gap.get("frequency", "1d")

            if not symbol or not gap_start or not gap_end or frequency != "1d":
                continue

            # æ£€æŸ¥è‚¡ç¥¨æ˜¯å¦é€‚åˆä¿®å¤ï¼ˆé¿å…ä¿®å¤æ–°è‚¡æˆ–åœç‰Œè‚¡çš„ç¼ºå£ï¼‰
            stock_info = self.db_manager.fetchone(
                "SELECT list_date, status FROM stocks WHERE symbol = ?", (symbol,)
            )

            if not stock_info:
                self.logger.debug(f"è·³è¿‡ä¿®å¤: {symbol} - è‚¡ç¥¨ä¿¡æ¯ä¸å­˜åœ¨")
                continue

            # æ£€æŸ¥ç¼ºå£æ˜¯å¦åœ¨è‚¡ç¥¨ä¸Šå¸‚æ—¥æœŸä¹‹å
            if stock_info["list_date"]:
                from datetime import datetime

                list_date = datetime.strptime(
                    stock_info["list_date"], "%Y-%m-%d"
                ).date()
                gap_start_date = datetime.strptime(gap_start, "%Y-%m-%d").date()

                if gap_start_date < list_date:
                    fix_result["skipped_fixes"] += 1
                    self.logger.debug(f"è·³è¿‡ä¿®å¤: {symbol} ç¼ºå£æ—¥æœŸæ—©äºä¸Šå¸‚æ—¥æœŸ")
                    continue

            fix_result["attempted_fixes"] += 1
            fixes_attempted += 1

            self.logger.info(f"ä¿®å¤ç¼ºå£: {symbol} {gap_start} åˆ° {gap_end}")

            # è·å–æ•°æ®å¡«è¡¥ç¼ºå£
            daily_data = self.data_source_manager.get_daily_data(
                symbol, gap_start, gap_end
            )

            if isinstance(daily_data, dict) and "data" in daily_data:
                daily_data = daily_data["data"]

            # å®é™…å¤„ç†æ•°æ®æ’å…¥
            if (
                daily_data is not None
                and hasattr(daily_data, "__len__")
                and len(daily_data) > 0
            ):
                try:
                    # ä½¿ç”¨å¤„ç†å¼•æ“æ’å…¥ç¼ºå£æ•°æ®
                    processed_result = self.processing_engine.process_symbol_data(
                        symbol, str(gap_start), str(gap_end), frequency
                    )
                    records_inserted = processed_result.get("records", 0)

                    if records_inserted > 0:
                        fix_result["successful_fixes"] += 1
                        self.logger.info(
                            f"ç¼ºå£ä¿®å¤æˆåŠŸ: {symbol} æ’å…¥{records_inserted}æ¡è®°å½•"
                        )
                    else:
                        fix_result["failed_fixes"] += 1
                        self.logger.warning(
                            f"ç¼ºå£ä¿®å¤å¤±è´¥: {symbol} å¤„ç†å¼•æ“æœªæ’å…¥æ•°æ®"
                        )
                except Exception as e:
                    fix_result["failed_fixes"] += 1
                    self.logger.warning(f"ç¼ºå£ä¿®å¤å‡ºé”™: {symbol} - {e}")
            else:
                fix_result["failed_fixes"] += 1
                self.logger.debug(f"ç¼ºå£ä¿®å¤è·³è¿‡: {symbol} æ•°æ®æºæ— æ•°æ®ï¼ˆå¯èƒ½æ­£å¸¸ï¼‰")

        self.logger.info(
            f"ç¼ºå£ä¿®å¤å®Œæˆ: å°è¯•={fix_result['attempted_fixes']}, æˆåŠŸ={fix_result['successful_fixes']}, å¤±è´¥={fix_result['failed_fixes']}, è·³è¿‡={fix_result['skipped_fixes']}"
        )

        # å¦‚æœå¤§éƒ¨åˆ†ç¼ºå£éƒ½æ— æ³•ä¿®å¤ï¼Œè¯´æ˜è¿™äº›ç¼ºå£å¯èƒ½æ˜¯æ­£å¸¸çš„
        if fix_result["attempted_fixes"] > 0:
            success_rate = (
                fix_result["successful_fixes"] / fix_result["attempted_fixes"]
            )
            if success_rate < 0.3:
                self.logger.info(
                    "ğŸ’¡ å¤§éƒ¨åˆ†ç¼ºå£æ— æ³•ä¿®å¤ï¼Œè¿™å¯èƒ½æ˜¯æ­£å¸¸ç°è±¡ï¼ˆæ–°è‚¡ã€åœç‰Œç­‰ï¼‰"
                )

        return fix_result

    def generate_sync_report(self, full_result: Dict[str, Any]) -> str:
        """ç”ŸæˆåŒæ­¥æŠ¥å‘Š"""
        report_lines = []

        # æŠ¥å‘Šå¤´éƒ¨
        report_lines.append("=" * 60)
        report_lines.append("æ•°æ®åŒæ­¥æŠ¥å‘Š")
        report_lines.append("=" * 60)
        report_lines.append(f"åŒæ­¥æ—¶é—´: {full_result.get('start_time', '')}")
        report_lines.append(f"ç›®æ ‡æ—¥æœŸ: {full_result.get('target_date', '')}")
        report_lines.append(f"æ€»è€—æ—¶: {full_result.get('duration_seconds', 0):.2f} ç§’")
        report_lines.append("")

        # é˜¶æ®µæ±‡æ€»
        summary = full_result.get("summary", {})
        report_lines.append("é˜¶æ®µæ±‡æ€»:")
        report_lines.append(f"  æ€»é˜¶æ®µæ•°: {summary.get('total_phases', 0)}")
        report_lines.append(f"  æˆåŠŸé˜¶æ®µ: {summary.get('successful_phases', 0)}")
        report_lines.append(f"  å¤±è´¥é˜¶æ®µ: {summary.get('failed_phases', 0)}")
        report_lines.append("")

        # å¢é‡åŒæ­¥è¯¦æƒ…
        phases = full_result.get("phases", {})
        if "incremental_sync" in phases:
            phase = phases["incremental_sync"]
            report_lines.append("å¢é‡åŒæ­¥:")
            report_lines.append(f"  çŠ¶æ€: {phase['status']}")

            if phase["status"] == "completed" and "result" in phase:
                result = phase["result"]
                report_lines.append(f"  æ€»è‚¡ç¥¨æ•°: {result.get('total_symbols', 0)}")
                report_lines.append(f"  æˆåŠŸæ•°é‡: {result.get('success_count', 0)}")
                report_lines.append(f"  é”™è¯¯æ•°é‡: {result.get('error_count', 0)}")
            elif "error" in phase:
                report_lines.append(f"  é”™è¯¯: {phase['error']}")

        return "\n".join(report_lines)
