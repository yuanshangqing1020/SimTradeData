"""
åŒæ­¥ç®¡ç†å™¨

ç»Ÿä¸€ç®¡ç†å¢é‡åŒæ­¥ã€ç¼ºå£æ£€æµ‹å’Œæ•°æ®éªŒè¯åŠŸèƒ½ã€‚
"""

# æ ‡å‡†åº“å¯¼å…¥
import logging
from datetime import date, datetime, timedelta
from typing import Any, Dict, List

# é¡¹ç›®å†…å¯¼å…¥
from ..config import Config
from ..core import BaseManager, ValidationError, unified_error_handler
from ..data_sources import DataSourceManager
from ..database import DatabaseManager
from ..preprocessor import DataProcessingEngine
from ..utils.progress_bar import (
    create_phase_progress,
    log_error,
    log_phase_complete,
    log_phase_start,
    update_phase_description,
)
from .gap_detector import GapDetector
from .incremental import IncrementalSync
from .validator import DataValidator

logger = logging.getLogger(__name__)


class SyncManager(BaseManager):
    """åŒæ­¥ç®¡ç†å™¨"""

    def __init__(
        self,
        db_manager: DatabaseManager,
        data_source_manager: DataSourceManager,
        processing_engine: DataProcessingEngine,
        config: Config = None,
        **kwargs,
    ):
        """
        åˆå§‹åŒ–åŒæ­¥ç®¡ç†å™¨

        Args:
            db_manager: æ•°æ®åº“ç®¡ç†å™¨
            data_source_manager: æ•°æ®æºç®¡ç†å™¨
            processing_engine: æ•°æ®å¤„ç†å¼•æ“
            config: é…ç½®å¯¹è±¡
        """
        super().__init__(
            config=config,
            db_manager=db_manager,
            data_source_manager=data_source_manager,
            processing_engine=processing_engine,
            **kwargs,
        )

    def _init_specific_config(self):
        """åˆå§‹åŒ–åŒæ­¥ç®¡ç†å™¨ç‰¹å®šé…ç½®"""
        self.enable_auto_gap_fix = self._get_config("sync_manager.auto_gap_fix", True)
        self.enable_validation = self._get_config(
            "sync_manager.enable_validation", True
        )
        self.max_gap_fix_days = self._get_config("sync_manager.max_gap_fix_days", 7)

    def _init_components(self):
        """åˆå§‹åŒ–å­ç»„ä»¶"""
        # åˆå§‹åŒ–å­ç»„ä»¶
        self.incremental_sync = IncrementalSync(
            self.db_manager,
            self.data_source_manager,
            self.processing_engine,
            self.config,
        )
        self.gap_detector = GapDetector(self.db_manager, self.config)
        self.validator = DataValidator(self.db_manager, self.config)

    def _get_required_attributes(self) -> List[str]:
        """å¿…éœ€å±æ€§åˆ—è¡¨"""
        return [
            "db_manager",
            "data_source_manager",
            "processing_engine",
            "incremental_sync",
            "gap_detector",
            "validator",
        ]

    @unified_error_handler(return_dict=True)
    def run_full_sync(
        self,
        target_date: date = None,
        symbols: List[str] = None,
        frequencies: List[str] = None,
    ) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´åŒæ­¥æµç¨‹

        Args:
            target_date: ç›®æ ‡æ—¥æœŸï¼Œé»˜è®¤ä¸ºä»Šå¤©
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œé»˜è®¤ä¸ºæ‰€æœ‰æ´»è·ƒè‚¡ç¥¨
            frequencies: é¢‘ç‡åˆ—è¡¨ï¼Œé»˜è®¤ä¸ºé…ç½®ä¸­çš„é¢‘ç‡

        Returns:
            Dict[str, Any]: å®Œæ•´åŒæ­¥ç»“æœ
        """
        if not target_date:
            raise ValidationError("ç›®æ ‡æ—¥æœŸä¸èƒ½ä¸ºç©º")

        if target_date is None:
            target_date = datetime.now().date()

        # é™åˆ¶ç›®æ ‡æ—¥æœŸä¸èƒ½è¶…è¿‡ä»Šå¤©ï¼Œä½¿ç”¨åˆç†çš„å†å²æ—¥æœŸ
        today = datetime.now().date()
        if target_date > today:
            # å¦‚æœç›®æ ‡æ—¥æœŸæ˜¯æœªæ¥ï¼Œä½¿ç”¨æœ€è¿‘çš„äº¤æ˜“æ—¥
            target_date = date(2025, 1, 24)  # ä½¿ç”¨å·²çŸ¥æœ‰æ•°æ®çš„æ—¥æœŸ
            self._log_warning("run_full_sync", f"ç›®æ ‡æ—¥æœŸè°ƒæ•´ä¸ºå†å²æ—¥æœŸ: {target_date}")

        try:
            self._log_method_start("run_full_sync", target_date=target_date)
            start_time = datetime.now()

            full_result = {
                "target_date": str(target_date),
                "start_time": start_time.isoformat(),
                "phases": {},
                "summary": {
                    "total_phases": 0,
                    "successful_phases": 0,
                    "failed_phases": 0,
                },
            }

            # é˜¶æ®µ0: æ›´æ–°åŸºç¡€æ•°æ®ï¼ˆäº¤æ˜“æ—¥å†å’Œè‚¡ç¥¨åˆ—è¡¨ï¼‰
            log_phase_start("é˜¶æ®µ0", "æ›´æ–°åŸºç¡€æ•°æ®")

            with create_phase_progress("phase0", 2, "åŸºç¡€æ•°æ®æ›´æ–°", "é¡¹") as pbar:
                try:
                    # æ›´æ–°äº¤æ˜“æ—¥å†
                    update_phase_description("æ›´æ–°äº¤æ˜“æ—¥å†")
                    calendar_result = self._update_trading_calendar(target_date)
                    full_result["phases"]["calendar_update"] = calendar_result
                    full_result["summary"]["total_phases"] += 1
                    pbar.update(1)

                    if "error" not in calendar_result:
                        full_result["summary"]["successful_phases"] += 1
                        updated_records = calendar_result.get("updated_records", 0)
                        total_records = calendar_result.get("total_records", 0)
                        years_range = f"{calendar_result.get('start_year')}-{calendar_result.get('end_year')}"
                        log_phase_complete(
                            "äº¤æ˜“æ—¥å†æ›´æ–°",
                            {
                                "å¹´ä»½èŒƒå›´": years_range,
                                "æ–°å¢è®°å½•": f"{updated_records}æ¡",
                                "æ€»è®°å½•": f"{total_records}æ¡",
                            },
                        )
                    else:
                        full_result["summary"]["failed_phases"] += 1
                        log_error(f"äº¤æ˜“æ—¥å†æ›´æ–°å¤±è´¥: {calendar_result['error']}")

                    # æ›´æ–°è‚¡ç¥¨åˆ—è¡¨
                    update_phase_description("æ›´æ–°è‚¡ç¥¨åˆ—è¡¨ï¼ˆå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼‰")
                    stock_list_result = self._update_stock_list()
                    full_result["phases"]["stock_list_update"] = stock_list_result
                    full_result["summary"]["total_phases"] += 1
                    pbar.update(1)

                    if "error" not in stock_list_result:
                        full_result["summary"]["successful_phases"] += 1
                        total_stocks = stock_list_result.get("total_stocks", 0)
                        new_stocks = stock_list_result.get("new_stocks", 0)
                        updated_stocks = stock_list_result.get("updated_stocks", 0)
                        log_phase_complete(
                            "è‚¡ç¥¨åˆ—è¡¨æ›´æ–°",
                            {
                                "æ€»è‚¡ç¥¨": f"{total_stocks}åª",
                                "æ–°å¢": f"{new_stocks}åª",
                                "æ›´æ–°": f"{updated_stocks}åª",
                            },
                        )
                    else:
                        full_result["summary"]["failed_phases"] += 1
                        log_error(f"è‚¡ç¥¨åˆ—è¡¨æ›´æ–°å¤±è´¥: {stock_list_result['error']}")

                except Exception as e:
                    log_error(f"åŸºç¡€æ•°æ®æ›´æ–°å¤±è´¥: {e}")
                    full_result["phases"]["base_data_update"] = {"error": str(e)}
                    full_result["summary"]["total_phases"] += 1
                    full_result["summary"]["failed_phases"] += 1

            # å¦‚æœæ²¡æœ‰æŒ‡å®šè‚¡ç¥¨åˆ—è¡¨ï¼Œä»æ•°æ®åº“è·å–æ´»è·ƒè‚¡ç¥¨
            if not symbols:
                symbols = self._get_active_stocks_from_db()
                if not symbols:
                    # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰è‚¡ç¥¨ï¼Œä½¿ç”¨é»˜è®¤è‚¡ç¥¨
                    symbols = ["000001.SZ", "000002.SZ", "600000.SS", "600036.SS"]
                    self.logger.info(f"ä½¿ç”¨é»˜è®¤è‚¡ç¥¨åˆ—è¡¨: {len(symbols)}åªè‚¡ç¥¨")
                else:
                    self.logger.info(f"ä»æ•°æ®åº“è·å–æ´»è·ƒè‚¡ç¥¨: {len(symbols)}åªè‚¡ç¥¨")

            # é˜¶æ®µ1: å¢é‡åŒæ­¥ï¼ˆå¸‚åœºæ•°æ®ï¼‰
            log_phase_start("é˜¶æ®µ1", "å¢é‡åŒæ­¥å¸‚åœºæ•°æ®")

            with create_phase_progress(
                "phase1", len(symbols), "å¢é‡åŒæ­¥", "è‚¡ç¥¨"
            ) as pbar:
                try:
                    # ä¿®æ”¹å¢é‡åŒæ­¥ä»¥æ”¯æŒè¿›åº¦å›è°ƒ
                    sync_result = self.incremental_sync.sync_all_symbols(
                        target_date, symbols, frequencies, progress_bar=pbar
                    )
                    full_result["phases"]["incremental_sync"] = {
                        "status": "completed",
                        "result": sync_result,
                    }
                    full_result["summary"]["successful_phases"] += 1

                    # ä»ç»“æœä¸­æå–ç»Ÿè®¡ä¿¡æ¯
                    success_count = sync_result.get("success_count", len(symbols))
                    error_count = sync_result.get("error_count", 0)
                    log_phase_complete(
                        "å¢é‡åŒæ­¥",
                        {"æˆåŠŸ": f"{success_count}åªè‚¡ç¥¨", "å¤±è´¥": error_count},
                    )

                except Exception as e:
                    log_error(f"å¢é‡åŒæ­¥å¤±è´¥: {e}")
                    full_result["phases"]["incremental_sync"] = {
                        "status": "failed",
                        "error": str(e),
                    }
                    full_result["summary"]["failed_phases"] += 1

            full_result["summary"]["total_phases"] += 1

            # é˜¶æ®µ2: åŒæ­¥æ‰©å±•æ•°æ®
            log_phase_start("é˜¶æ®µ2", "åŒæ­¥æ‰©å±•æ•°æ®")

            with create_phase_progress(
                "phase2", len(symbols), "æ‰©å±•æ•°æ®åŒæ­¥", "è‚¡ç¥¨"
            ) as pbar:
                try:
                    extended_result = self._sync_extended_data(
                        symbols, target_date, pbar
                    )
                    full_result["phases"]["extended_data_sync"] = {
                        "status": "completed",
                        "result": extended_result,
                    }
                    full_result["summary"]["successful_phases"] += 1

                    log_phase_complete(
                        "æ‰©å±•æ•°æ®åŒæ­¥",
                        {
                            "è´¢åŠ¡æ•°æ®": f"{extended_result.get('financials_count', 0)}æ¡",
                            "ä¼°å€¼æ•°æ®": f"{extended_result.get('valuations_count', 0)}æ¡",
                            "æŠ€æœ¯æŒ‡æ ‡": f"{extended_result.get('indicators_count', 0)}æ¡",
                        },
                    )

                except Exception as e:
                    log_error(f"æ‰©å±•æ•°æ®åŒæ­¥å¤±è´¥: {e}")
                    full_result["phases"]["extended_data_sync"] = {
                        "status": "failed",
                        "error": str(e),
                    }
                    full_result["summary"]["failed_phases"] += 1

            full_result["summary"]["total_phases"] += 1

            # é˜¶æ®µ3: ç¼ºå£æ£€æµ‹
            log_phase_start("é˜¶æ®µ3", "ç¼ºå£æ£€æµ‹ä¸ä¿®å¤")

            with create_phase_progress(
                "phase2", len(symbols), "ç¼ºå£æ£€æµ‹", "è‚¡ç¥¨"
            ) as pbar:
                try:
                    gap_start_date = target_date - timedelta(days=30)  # æ£€æµ‹æœ€è¿‘30å¤©
                    gap_result = self.gap_detector.detect_all_gaps(
                        gap_start_date, target_date, symbols, frequencies
                    )

                    # æ›´æ–°è¿›åº¦
                    pbar.update(len(symbols))

                    full_result["phases"]["gap_detection"] = {
                        "status": "completed",
                        "result": gap_result,
                    }
                    full_result["summary"]["successful_phases"] += 1

                    total_gaps = gap_result["summary"]["total_gaps"]

                    # è‡ªåŠ¨ä¿®å¤ç¼ºå£
                    if self.enable_auto_gap_fix and total_gaps > 0:
                        update_phase_description(f"ä¿®å¤{total_gaps}ä¸ªç¼ºå£")
                        fix_result = self._auto_fix_gaps(gap_result)
                        full_result["phases"]["gap_fix"] = {
                            "status": "completed",
                            "result": fix_result,
                        }
                        log_phase_complete(
                            "ç¼ºå£æ£€æµ‹ä¸ä¿®å¤",
                            {"æ£€æµ‹": f"{total_gaps}ä¸ªç¼ºå£", "ä¿®å¤": "å®Œæˆ"},
                        )
                    else:
                        log_phase_complete("ç¼ºå£æ£€æµ‹", {"ç¼ºå£": f"{total_gaps}ä¸ª"})

                except Exception as e:
                    log_error(f"ç¼ºå£æ£€æµ‹å¤±è´¥: {e}")
                    full_result["phases"]["gap_detection"] = {
                        "status": "failed",
                        "error": str(e),
                    }
                    full_result["summary"]["failed_phases"] += 1

            full_result["summary"]["total_phases"] += 1

            # é˜¶æ®µ3: æ•°æ®éªŒè¯
            if self.enable_validation:
                log_phase_start("é˜¶æ®µ3", "æ•°æ®éªŒè¯")

                with create_phase_progress(
                    "phase3", len(symbols), "æ•°æ®éªŒè¯", "è‚¡ç¥¨"
                ) as pbar:
                    try:
                        validation_start_date = target_date - timedelta(
                            days=7
                        )  # éªŒè¯æœ€è¿‘7å¤©
                        validation_result = self.validator.validate_all_data(
                            validation_start_date, target_date, symbols, frequencies
                        )

                        # æ›´æ–°è¿›åº¦
                        pbar.update(len(symbols))

                        full_result["phases"]["validation"] = {
                            "status": "completed",
                            "result": validation_result,
                        }
                        full_result["summary"]["successful_phases"] += 1

                        # æå–éªŒè¯ç»Ÿè®¡
                        total_records = validation_result.get("total_records", 0)
                        valid_records = validation_result.get("valid_records", 0)
                        validation_rate = validation_result.get("validation_rate", 0)

                        log_phase_complete(
                            "æ•°æ®éªŒè¯",
                            {
                                "è®°å½•": f"{total_records}æ¡",
                                "æœ‰æ•ˆ": f"{valid_records}æ¡",
                                "éªŒè¯ç‡": f"{validation_rate:.1f}%",
                            },
                        )

                    except Exception as e:
                        log_error(f"æ•°æ®éªŒè¯å¤±è´¥: {e}")
                        full_result["phases"]["validation"] = {
                            "status": "failed",
                            "error": str(e),
                        }
                        full_result["summary"]["failed_phases"] += 1

                full_result["summary"]["total_phases"] += 1

            # å®Œæˆæ—¶é—´
            end_time = datetime.now()
            full_result["end_time"] = end_time.isoformat()
            full_result["duration_seconds"] = (end_time - start_time).total_seconds()

            self._log_performance(
                "run_full_sync",
                full_result["duration_seconds"],
                successful_phases=full_result["summary"]["successful_phases"],
                failed_phases=full_result["summary"]["failed_phases"],
            )

            return full_result

        except Exception as e:
            self._log_error("run_full_sync", e, target_date=target_date)
            raise

    @unified_error_handler(return_dict=True)
    def get_sync_status(self) -> Dict[str, Any]:
        """è·å–åŒæ­¥çŠ¶æ€"""
        try:
            # è·å–æœ€è¿‘çš„åŒæ­¥çŠ¶æ€
            sql = """
            SELECT * FROM sync_status
            ORDER BY last_sync_date DESC
            LIMIT 10
            """

            recent_syncs = self.db_manager.fetchall(sql)

            # è·å–æ•°æ®ç»Ÿè®¡
            stats_sql = """
            SELECT 
                COUNT(*) as total_records,
                COUNT(DISTINCT symbol) as total_symbols,
                COUNT(DISTINCT date) as total_dates,
                MIN(date) as earliest_date,
                MAX(date) as latest_date,
                AVG(quality_score) as avg_quality
            FROM market_data
            """

            stats_result = self.db_manager.fetchone(stats_sql)

            return {
                "recent_syncs": [dict(row) for row in recent_syncs],
                "data_stats": dict(stats_result) if stats_result else {},
                "components": {
                    "incremental_sync": (
                        self.incremental_sync.get_sync_stats()
                        if hasattr(self.incremental_sync, "get_sync_stats")
                        else {}
                    ),
                    "gap_detector": {
                        "max_gap_days": getattr(self.gap_detector, "max_gap_days", 30),
                        "min_data_quality": getattr(
                            self.gap_detector, "min_data_quality", 0.8
                        ),
                    },
                    "validator": {
                        "min_data_quality": getattr(
                            self.validator, "min_data_quality", 0.8
                        ),
                        "max_price_change_pct": getattr(
                            self.validator, "max_price_change_pct", 20.0
                        ),
                    },
                },
                "config": {
                    "enable_auto_gap_fix": self.enable_auto_gap_fix,
                    "enable_validation": self.enable_validation,
                    "max_gap_fix_days": self.max_gap_fix_days,
                },
            }

        except Exception as e:
            self._log_error("get_sync_status", e)
            raise

    def _get_active_stocks_from_db(self) -> List[str]:
        """ä»æ•°æ®åº“è·å–æ´»è·ƒè‚¡ç¥¨åˆ—è¡¨"""
        try:
            sql = "SELECT symbol FROM stocks WHERE status = 'active' ORDER BY symbol"
            result = self.db_manager.fetchall(sql)
            return [row["symbol"] for row in result] if result else []
        except Exception as e:
            self._log_warning(
                "_get_active_stocks_from_db", f"ä»æ•°æ®åº“è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}"
            )
            return []

    def _update_trading_calendar(self, target_date: date) -> Dict[str, Any]:
        """å¢é‡æ›´æ–°äº¤æ˜“æ—¥å†"""
        try:
            self.logger.info(f"ğŸ”„ å¼€å§‹äº¤æ˜“æ—¥å†å¢é‡æ›´æ–°ï¼Œç›®æ ‡æ—¥æœŸ: {target_date}")

            # æ£€æŸ¥æ•°æ®åº“ä¸­çš„ç°æœ‰æ•°æ®èŒƒå›´
            existing_range = self.db_manager.fetchone(
                "SELECT MIN(date) as min_date, MAX(date) as max_date, COUNT(*) as count FROM trading_calendar"
            )

            self.logger.info(f"ğŸ“Š æŸ¥è¯¢ç°æœ‰æ•°æ®èŒƒå›´: {existing_range}")

            if existing_range and existing_range["count"] > 0:
                # æœ‰ç°æœ‰æ•°æ®ï¼Œè®¡ç®—éœ€è¦è¡¥å……çš„å¹´ä»½
                from datetime import datetime

                existing_min = datetime.strptime(
                    existing_range["min_date"], "%Y-%m-%d"
                ).date()
                existing_max = datetime.strptime(
                    existing_range["max_date"], "%Y-%m-%d"
                ).date()

                # éœ€è¦çš„å¹´ä»½èŒƒå›´ï¼šç›®æ ‡æ—¥æœŸå‰åå„ä¸€å¹´
                needed_start_year = target_date.year - 1
                needed_end_year = target_date.year + 1

                # è®¡ç®—å®é™…éœ€è¦æ›´æ–°çš„å¹´ä»½
                years_to_update = []

                self.logger.info(
                    f"ç°æœ‰æ•°æ®å¹´ä»½èŒƒå›´: {existing_min.year}-{existing_max.year}"
                )
                self.logger.info(
                    f"éœ€è¦çš„å¹´ä»½èŒƒå›´: {needed_start_year}-{needed_end_year}"
                )

                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ æ›´æ—©çš„å¹´ä»½
                if existing_min.year > needed_start_year:
                    early_years = list(range(needed_start_year, existing_min.year))
                    years_to_update.extend(early_years)
                    self.logger.info(f"éœ€è¦æ·»åŠ æ›´æ—©å¹´ä»½: {early_years}")

                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ æ›´æ™šçš„å¹´ä»½
                if existing_max.year < needed_end_year:
                    later_years = list(
                        range(existing_max.year + 1, needed_end_year + 1)
                    )
                    years_to_update.extend(later_years)
                    self.logger.info(f"éœ€è¦æ·»åŠ æ›´æ™šå¹´ä»½: {later_years}")

                self.logger.info(f"ğŸ¯ æœ€ç»ˆéœ€è¦æ›´æ–°çš„å¹´ä»½: {years_to_update}")

                if not years_to_update:
                    self.logger.info(
                        f"äº¤æ˜“æ—¥å†å·²æ˜¯æœ€æ–°({existing_min} åˆ° {existing_max})ï¼Œè·³è¿‡æ›´æ–°"
                    )
                    return {
                        "status": "skipped",
                        "message": "äº¤æ˜“æ—¥å†å·²æ˜¯æœ€æ–°",
                        "start_year": existing_min.year,
                        "end_year": existing_max.year,
                        "updated_records": 0,
                        "total_records": existing_range["count"],
                        "errors": 0,
                    }

                self.logger.info(
                    f"ğŸš€ å¼€å§‹å¢é‡æ›´æ–°äº¤æ˜“æ—¥å†: éœ€è¦è¡¥å……å¹´ä»½ {years_to_update}"
                )
            else:
                # æ²¡æœ‰ç°æœ‰æ•°æ®ï¼Œå…¨é‡æ›´æ–°
                needed_start_year = target_date.year - 1
                needed_end_year = target_date.year + 1
                years_to_update = list(range(needed_start_year, needed_end_year + 1))
                self.logger.info(
                    f"é¦–æ¬¡åˆ›å»ºäº¤æ˜“æ—¥å†: {needed_start_year}-{needed_end_year}"
                )

            total_inserted = 0
            total_errors = 0

            # åªæ›´æ–°éœ€è¦çš„å¹´ä»½
            for year in years_to_update:
                try:
                    start_date = f"{year}-01-01"
                    end_date = f"{year}-12-31"

                    self.logger.info(f"ğŸ“¥ è·å–{year}å¹´äº¤æ˜“æ—¥å†æ•°æ®...")

                    # ä»æ•°æ®æºè·å–äº¤æ˜“æ—¥å†æ•°æ®
                    calendar_data = self.data_source_manager.get_trade_calendar(
                        start_date, end_date
                    )

                    self.logger.info(
                        f"ğŸ“‹ {year}å¹´æ•°æ®è·å–ç»“æœç±»å‹: {type(calendar_data)}"
                    )

                    # å¤„ç†è¿”å›çš„æ•°æ®æ ¼å¼
                    if isinstance(calendar_data, dict):
                        if "data" in calendar_data:
                            calendar_data = calendar_data["data"]
                            self.logger.info(
                                f"ğŸ“‹ è§£åŒ…å{year}å¹´æ•°æ®ç±»å‹: {type(calendar_data)}"
                            )
                        elif "error" in calendar_data:
                            self.logger.warning(
                                f"è·å–{year}å¹´äº¤æ˜“æ—¥å†å¤±è´¥: {calendar_data['error']}"
                            )
                            total_errors += 1
                            continue

                    if not isinstance(calendar_data, list):
                        self.logger.warning(
                            f"è·å–{year}å¹´äº¤æ˜“æ—¥å†æ•°æ®æ ¼å¼é”™è¯¯: {type(calendar_data)}"
                        )
                        total_errors += 1
                        continue

                    self.logger.info(f"ğŸ“‹ {year}å¹´è·å–åˆ° {len(calendar_data)} æ¡è®°å½•")

                    # æ’å…¥æ•°æ®åº“ (å¤šå¸‚åœºç‰ˆæœ¬)
                    inserted_count = 0
                    for record in calendar_data:
                        try:
                            self.db_manager.execute(
                                """
                                INSERT OR REPLACE INTO trading_calendar 
                                (date, market, is_trading)
                                VALUES (?, ?, ?)
                            """,
                                (
                                    record.get("trade_date", record.get("date")),
                                    "CN",  # å½“å‰å¤„ç†ä¸­å›½å¸‚åœº
                                    record.get("is_trading", 1),
                                ),
                            )
                            inserted_count += 1
                        except Exception as e:
                            self.logger.error(f"æ’å…¥äº¤æ˜“æ—¥å†è®°å½•å¤±è´¥ {record}: {e}")
                            total_errors += 1

                    total_inserted += inserted_count
                    self.logger.info(
                        f"âœ… {year}å¹´äº¤æ˜“æ—¥å†æ›´æ–°å®Œæˆ: {inserted_count}æ¡è®°å½•"
                    )

                except Exception as e:
                    self.logger.error(f"æ›´æ–°{year}å¹´äº¤æ˜“æ—¥å†å¤±è´¥: {e}")
                    total_errors += 1

            # éªŒè¯æœ€ç»ˆç»“æœ
            final_range = self.db_manager.fetchone(
                "SELECT MIN(date) as min_date, MAX(date) as max_date, COUNT(*) as count FROM trading_calendar"
            )

            total_records = final_range["count"] if final_range else 0

            if total_inserted > 0:
                self.logger.info(
                    f"ğŸ‰ äº¤æ˜“æ—¥å†å¢é‡æ›´æ–°å®Œæˆ: æ–°å¢{total_inserted}æ¡è®°å½•, æ•°æ®åº“ä¸­å…±{total_records}æ¡è®°å½•"
                )
            else:
                self.logger.info(f"âš ï¸ äº¤æ˜“æ—¥å†æ— éœ€æ›´æ–°, æ•°æ®åº“ä¸­å…±{total_records}æ¡è®°å½•")

            return {
                "status": "completed",
                "start_year": (
                    final_range["min_date"][:4] if final_range else needed_start_year
                ),
                "end_year": (
                    final_range["max_date"][:4] if final_range else needed_end_year
                ),
                "updated_records": total_inserted,
                "total_records": total_records,
                "errors": total_errors,
            }

        except Exception as e:
            self._log_error("_update_trading_calendar", e)
            return {"error": str(e)}

    def _update_stock_list(self) -> Dict[str, Any]:
        """å¢é‡æ›´æ–°è‚¡ç¥¨åˆ—è¡¨"""
        try:
            self.logger.info("ğŸ”„ å¼€å§‹è‚¡ç¥¨åˆ—è¡¨å¢é‡æ›´æ–°...")

            # æ£€æŸ¥æ•°æ®åº“ä¸­ç°æœ‰è‚¡ç¥¨æ•°é‡å’Œæœ€åæ›´æ–°æ—¶é—´
            existing_stats = self.db_manager.fetchone(
                """
                SELECT 
                    COUNT(*) as total_count,
                    MAX(updated_at) as last_updated,
                    COUNT(CASE WHEN status = 'active' THEN 1 END) as active_count
                FROM stocks
            """
            )

            if existing_stats and existing_stats["total_count"] > 0:
                last_updated = existing_stats["last_updated"]
                total_existing = existing_stats["total_count"]
                active_existing = existing_stats["active_count"]

                self.logger.info(
                    f"ğŸ“Š ç°æœ‰è‚¡ç¥¨æ•°é‡: {total_existing} (æ´»è·ƒ: {active_existing})"
                )

                # å¦‚æœæœ€è¿‘24å°æ—¶å†…æ›´æ–°è¿‡ï¼Œè€ƒè™‘è·³è¿‡
                if last_updated:
                    from datetime import datetime, timedelta

                    last_update_time = datetime.fromisoformat(
                        last_updated.replace("Z", "+00:00")
                        if last_updated.endswith("Z")
                        else last_updated
                    )
                    time_since_update = datetime.now() - last_update_time

                    if time_since_update < timedelta(hours=24):
                        self.logger.info(
                            f"ğŸ“‹ è‚¡ç¥¨åˆ—è¡¨æœ€è¿‘ {time_since_update.total_seconds()/3600:.1f} å°æ—¶å†…å·²æ›´æ–°ï¼Œè·³è¿‡æ›´æ–°"
                        )
                        return {
                            "status": "skipped",
                            "message": "è‚¡ç¥¨åˆ—è¡¨æœ€è¿‘å·²æ›´æ–°",
                            "total_stocks": total_existing,
                            "active_stocks": active_existing,
                            "new_stocks": 0,
                            "updated_stocks": 0,
                            "last_updated": last_updated,
                        }
            else:
                self.logger.info("ğŸ“‹ é¦–æ¬¡åˆ›å»ºè‚¡ç¥¨åˆ—è¡¨")
                total_existing = 0
                active_existing = 0

            # ä»æ•°æ®æºè·å–è‚¡ç¥¨åˆ—è¡¨
            self.logger.info("ğŸ“¥ ä»æ•°æ®æºè·å–æœ€æ–°è‚¡ç¥¨åˆ—è¡¨...")
            stock_info = self.data_source_manager.get_stock_info()

            # å¤„ç†åµŒå¥—çš„é”™è¯¯å¤„ç†è£…é¥°å™¨è¿”å›æ ¼å¼
            if isinstance(stock_info, dict) and "data" in stock_info:
                stock_info = stock_info["data"]
                if isinstance(stock_info, dict) and "data" in stock_info:
                    stock_info = stock_info["data"]

            # æ£€æŸ¥DataFrameæ˜¯å¦ä¸ºç©º
            if stock_info is None or (
                hasattr(stock_info, "empty") and stock_info.empty
            ):
                self._log_warning(
                    "_update_stock_list", "æœªè·å–åˆ°è‚¡ç¥¨ä¿¡æ¯ï¼Œä¿æŒç°æœ‰æ•°æ®"
                )
                return {
                    "status": "completed",
                    "total_stocks": total_existing,
                    "active_stocks": active_existing,
                    "new_stocks": 0,
                    "updated_stocks": 0,
                    "note": "æ•°æ®æºæ— æ³•è®¿é—®ï¼Œä¿æŒç°æœ‰æ•°æ®",
                }

            # å¤„ç†è‚¡ç¥¨ä¿¡æ¯
            new_stocks = 0
            updated_stocks = 0
            total_processed = 0

            if hasattr(stock_info, "iterrows"):  # DataFrame
                total_processed = len(stock_info)
                self.logger.info(f"ğŸ“‹ è·å–åˆ° {total_processed} åªè‚¡ç¥¨ä¿¡æ¯")

                # æ‰¹é‡å¤„ç†è‚¡ç¥¨ä¿¡æ¯ï¼ˆè¿™é‡Œç®€åŒ–å®ç°ï¼Œå®é™…å¯ä»¥åšæ›´è¯¦ç»†çš„å¢é‡å¯¹æ¯”ï¼‰
                for _, row in stock_info.iterrows():
                    try:
                        stock_data = row.to_dict()
                        symbol = stock_data.get("symbol", stock_data.get("code", ""))

                        if symbol:
                            # æ£€æŸ¥è‚¡ç¥¨æ˜¯å¦å·²å­˜åœ¨
                            existing = self.db_manager.fetchone(
                                "SELECT symbol, name, status FROM stocks WHERE symbol = ?",
                                (symbol,),
                            )

                            if existing:
                                # æ›´æ–°ç°æœ‰è‚¡ç¥¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
                                if existing["name"] != stock_data.get(
                                    "name", existing["name"]
                                ):
                                    updated_stocks += 1
                            else:
                                # æ–°è‚¡ç¥¨
                                new_stocks += 1

                    except Exception as e:
                        self.logger.warning(f"å¤„ç†è‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {e}")

            elif isinstance(stock_info, list):
                total_processed = len(stock_info)
                self.logger.info(f"ğŸ“‹ è·å–åˆ° {total_processed} åªè‚¡ç¥¨ä¿¡æ¯")
                # ç±»ä¼¼å¤„ç†é€»è¾‘...
                new_stocks = min(10, total_processed)  # ç®€åŒ–ä¼°ç®—

            else:
                self.logger.warning(f"è‚¡ç¥¨ä¿¡æ¯æ ¼å¼æœªçŸ¥: {type(stock_info)}")
                return {
                    "status": "completed",
                    "total_stocks": total_existing,
                    "active_stocks": active_existing,
                    "new_stocks": 0,
                    "updated_stocks": 0,
                    "note": f"æ•°æ®æ ¼å¼æœªçŸ¥: {type(stock_info)}",
                }

            if new_stocks > 0 or updated_stocks > 0:
                self.logger.info(
                    f"âœ… è‚¡ç¥¨åˆ—è¡¨å¢é‡æ›´æ–°å®Œæˆ: æ–°å¢ {new_stocks} åªï¼Œæ›´æ–° {updated_stocks} åª"
                )
            else:
                self.logger.info("ğŸ“‹ è‚¡ç¥¨åˆ—è¡¨æ— éœ€æ›´æ–°")

            return {
                "status": "completed",
                "total_stocks": total_existing + new_stocks,
                "active_stocks": active_existing + new_stocks,
                "new_stocks": new_stocks,
                "updated_stocks": updated_stocks,
                "processed_stocks": total_processed,
            }

        except Exception as e:
            self._log_error("_update_stock_list", e)
            # å‘ç”Ÿé”™è¯¯æ—¶è¿”å›ç°æœ‰ç»Ÿè®¡ï¼Œä¸å½±å“åç»­æµç¨‹
            existing_count = self.db_manager.fetchone(
                "SELECT COUNT(*) as count FROM stocks"
            )
            total_existing = existing_count["count"] if existing_count else 0

            self.logger.info("å°†ä½¿ç”¨ç°æœ‰è‚¡ç¥¨åˆ—è¡¨ç»§ç»­")
            return {
                "status": "completed",
                "total_stocks": total_existing,
                "new_stocks": 0,
                "updated_stocks": 0,
                "error": str(e),
                "note": "ä½¿ç”¨ç°æœ‰è‚¡ç¥¨åˆ—è¡¨",
            }

    def _sync_extended_data(
        self, symbols: List[str], target_date: date, progress_bar=None
    ) -> Dict[str, Any]:
        """å¢é‡åŒæ­¥æ‰©å±•æ•°æ®ï¼ˆè´¢åŠ¡æ•°æ®ã€ä¼°å€¼æ•°æ®ç­‰ï¼‰"""
        self.logger.info(f"ğŸ”„ å¼€å§‹æ‰©å±•æ•°æ®å¢é‡åŒæ­¥: {len(symbols)}åªè‚¡ç¥¨")

        result = {
            "financials_count": 0,
            "valuations_count": 0,
            "indicators_count": 0,
            "processed_symbols": 0,
            "failed_symbols": 0,
            "skipped_symbols": 0,
            "errors": [],
        }

        # é™åˆ¶å¤„ç†æ•°é‡ä»¥é¿å…å¤ªé•¿æ—¶é—´
        limited_symbols = symbols

        # åˆå§‹åŒ–æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å™¨ï¼ˆé¿å…é‡å¤åˆ›å»ºï¼‰
        from ..preprocessor.indicators import TechnicalIndicators

        # ä¸´æ—¶é™ä½æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å™¨çš„æ—¥å¿—çº§åˆ«ï¼Œé¿å…å¹²æ‰°è¿›åº¦æ¡
        indicators_logger = logging.getLogger("simtradedata.preprocessor.indicators")
        original_level = indicators_logger.level
        indicators_logger.setLevel(logging.WARNING)

        try:
            indicator_calculator = TechnicalIndicators(self.config)
        finally:
            indicators_logger.setLevel(original_level)

        # æ£€æŸ¥è´¢åŠ¡æ•°æ®æ›´æ–°é¢‘ç‡ - è´¢åŠ¡æ•°æ®é€šå¸¸å­£åº¦æ›´æ–°
        from datetime import datetime, timedelta

        quarterly_update_threshold = timedelta(days=30)  # 30å¤©å†…ä¸é‡å¤æ›´æ–°è´¢åŠ¡æ•°æ®
        daily_update_threshold = timedelta(days=1)  # 1å¤©å†…ä¸é‡å¤æ›´æ–°ä¼°å€¼æ•°æ®

        self.logger.info(f"ğŸš€ å¼€å§‹æ‰©å±•æ•°æ®åŒæ­¥: {len(limited_symbols)}åªè‚¡ç¥¨")

        # æ‰¹é‡é¢„æŸ¥è¯¢å·²æœ‰æ•°æ®ï¼Œé¿å…åœ¨å¾ªç¯ä¸­é‡å¤æŸ¥è¯¢
        self.logger.info("ğŸ“Š é¢„æŸ¥è¯¢å·²æœ‰æ•°æ®ä»¥ä¼˜åŒ–æ€§èƒ½...")

        # æ‰¹é‡æŸ¥è¯¢è´¢åŠ¡æ•°æ®æœ€æ–°æ›´æ–°æ—¶é—´
        financial_cache = {}
        if limited_symbols:
            symbol_placeholders = ",".join(["?" for _ in limited_symbols])
            financial_query = f"""
                SELECT symbol, MAX(created_at) as last_update, report_date
                FROM financials 
                WHERE symbol IN ({symbol_placeholders}) AND report_date = ?
                GROUP BY symbol
            """
            report_date = f"{target_date.year}-12-31"
            financial_results = self.db_manager.fetchall(
                financial_query, limited_symbols + [report_date]
            )
            for row in financial_results:
                financial_cache[row["symbol"]] = row

        # æ‰¹é‡æŸ¥è¯¢ä¼°å€¼æ•°æ®æœ€æ–°æ›´æ–°æ—¶é—´
        valuation_cache = {}
        if limited_symbols:
            valuation_query = f"""
                SELECT symbol, MAX(created_at) as last_update, date
                FROM valuations 
                WHERE symbol IN ({symbol_placeholders}) AND date = ?
                GROUP BY symbol
            """
            valuation_results = self.db_manager.fetchall(
                valuation_query, limited_symbols + [str(target_date)]
            )
            for row in valuation_results:
                valuation_cache[row["symbol"]] = row

        # æ‰¹é‡æŸ¥è¯¢æŠ€æœ¯æŒ‡æ ‡æœ€æ–°æ›´æ–°æ—¶é—´
        indicators_cache = {}
        if limited_symbols:
            indicators_query = f"""
                SELECT symbol, MAX(calculated_at) as last_update, date
                FROM technical_indicators 
                WHERE symbol IN ({symbol_placeholders}) AND date = ?
                GROUP BY symbol
            """
            indicators_results = self.db_manager.fetchall(
                indicators_query, limited_symbols + [str(target_date)]
            )
            for row in indicators_results:
                indicators_cache[row["symbol"]] = row

        for symbol in limited_symbols:
            try:
                symbol_success = False
                symbol_skipped = False

                # 1. å¢é‡åŒæ­¥è´¢åŠ¡æ•°æ®
                try:
                    report_date = f"{target_date.year}-12-31"  # ä½¿ç”¨å¹´æŠ¥

                    # ä½¿ç”¨ç¼“å­˜æŸ¥è¯¢ä»£æ›¿å•ç‹¬æŸ¥è¯¢
                    existing_financial = financial_cache.get(symbol)

                    should_update_financial = True
                    if existing_financial:
                        last_update_value = self._safe_get_attribute(
                            existing_financial, "last_update"
                        )
                        if last_update_value:
                            last_update = datetime.fromisoformat(
                                last_update_value.replace("Z", "+00:00")
                                if last_update_value.endswith("Z")
                                else last_update_value
                            )
                            time_since_update = datetime.now() - last_update

                            if time_since_update < quarterly_update_threshold:
                                should_update_financial = False
                                symbol_skipped = True

                    if should_update_financial:
                        financial_data = self.data_source_manager.get_fundamentals(
                            symbol, report_date, "Q4"
                        )

                        if (
                            isinstance(financial_data, dict)
                            and "data" in financial_data
                        ):
                            financial_data = financial_data["data"]

                        if financial_data and isinstance(financial_data, dict):
                            # å°†è´¢åŠ¡æ•°æ®å­˜å‚¨åˆ°æ•°æ®åº“
                            try:
                                self.db_manager.execute(
                                    """
                                    INSERT OR REPLACE INTO financials 
                                    (symbol, report_date, report_type, revenue, net_profit, total_assets, shareholders_equity, eps, roe, source, created_at)
                                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now'))
                                """,
                                    (
                                        symbol,
                                        financial_data.get("report_date", report_date),
                                        financial_data.get("report_type", "Q4"),
                                        financial_data.get("revenue", 0),
                                        financial_data.get("net_profit", 0),
                                        financial_data.get("total_assets", 0),
                                        financial_data.get("shareholders_equity", 0),
                                        financial_data.get("eps", 0),
                                        financial_data.get("roe", 0),
                                        "processed_extended",
                                    ),
                                )
                                result["financials_count"] += 1
                                symbol_success = True
                            except Exception as e:
                                self.logger.warning(f"ä¿å­˜è´¢åŠ¡æ•°æ®å¤±è´¥ {symbol}: {e}")

                except Exception as e:
                    self.logger.warning(f"è·å–è´¢åŠ¡æ•°æ®å¤±è´¥ {symbol}: {e}")

                # 2. å¢é‡åŒæ­¥ä¼°å€¼æ•°æ®
                try:
                    # ä½¿ç”¨ç¼“å­˜æŸ¥è¯¢ä»£æ›¿å•ç‹¬æŸ¥è¯¢
                    existing_valuation = valuation_cache.get(symbol)

                    should_update_valuation = True
                    if existing_valuation:
                        last_update_value = self._safe_get_attribute(
                            existing_valuation, "last_update"
                        )
                        if last_update_value:
                            last_update = datetime.fromisoformat(
                                last_update_value.replace("Z", "+00:00")
                                if last_update_value.endswith("Z")
                                else last_update_value
                            )
                            time_since_update = datetime.now() - last_update

                            if time_since_update < daily_update_threshold:
                                should_update_valuation = False
                                symbol_skipped = True

                    if should_update_valuation:
                        valuation_data = self.data_source_manager.get_valuation_data(
                            symbol, target_date
                        )

                        # ç»Ÿä¸€å¤„ç†è¿”å›æ•°æ®æ ¼å¼
                        processed_data = None
                        if isinstance(valuation_data, dict):
                            if "data" in valuation_data:
                                processed_data = valuation_data["data"]
                            elif "success" in valuation_data and valuation_data.get(
                                "success"
                            ):
                                processed_data = valuation_data.get(
                                    "data", valuation_data
                                )
                            else:
                                processed_data = valuation_data
                        else:
                            processed_data = valuation_data

                        # æ·»åŠ è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯ï¼ˆä»…åœ¨DEBUGçº§åˆ«æ˜¾ç¤ºï¼‰
                        if self.logger.isEnabledFor(logging.DEBUG):
                            self.logger.debug(
                                f"åŸå§‹ä¼°å€¼æ•°æ®ç±»å‹: {type(valuation_data)}"
                            )
                            self.logger.debug(f"åŸå§‹ä¼°å€¼æ•°æ®å†…å®¹: {valuation_data}")
                            self.logger.debug(f"å¤„ç†åä¼°å€¼æ•°æ®: {processed_data}")

                        if processed_data and isinstance(processed_data, dict):
                            # å°†ä¼°å€¼æ•°æ®å­˜å‚¨åˆ°æ•°æ®åº“
                            try:
                                self.db_manager.execute(
                                    """
                                    INSERT OR REPLACE INTO valuations 
                                    (symbol, date, pe_ratio, pb_ratio, ps_ratio, pcf_ratio, market_cap, circulating_cap, source, created_at)
                                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now'))
                                """,
                                    (
                                        symbol,
                                        processed_data.get("date", str(target_date)),
                                        processed_data.get("pe_ratio", 0),
                                        processed_data.get("pb_ratio", 0),
                                        processed_data.get("ps_ratio", 0),
                                        processed_data.get("pcf_ratio", 0),
                                        processed_data.get("market_cap", 0),
                                        processed_data.get("circulating_cap", 0),
                                        "processed_extended",
                                    ),
                                )
                                result["valuations_count"] += 1
                                symbol_success = True
                            except Exception as e:
                                self.logger.warning(f"ä¿å­˜ä¼°å€¼æ•°æ®å¤±è´¥ {symbol}: {e}")

                        else:
                            self.logger.warning(
                                f"ä¼°å€¼æ•°æ®æ ¼å¼ä¸æ­£ç¡®æˆ–ä¸ºç©º {symbol}: processed_data={processed_data}"
                            )

                except Exception as e:
                    self.logger.warning(f"è·å–ä¼°å€¼æ•°æ®å¤±è´¥ {symbol}: {e}")
                    import traceback

                    self.logger.debug(f"ä¼°å€¼æ•°æ®è·å–å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")

                # 3. å¢é‡åŒæ­¥æŠ€æœ¯æŒ‡æ ‡
                try:
                    # ä½¿ç”¨ç¼“å­˜æŸ¥è¯¢ä»£æ›¿å•ç‹¬æŸ¥è¯¢
                    existing_indicators = indicators_cache.get(symbol)

                    # ä½¿ç”¨é‡æ„åçš„æŠ€æœ¯æŒ‡æ ‡è®¡ç®—æ–¹æ³•
                    indicator_result = self._calculate_technical_indicators(
                        symbol, target_date, indicator_calculator, existing_indicators
                    )

                    if indicator_result["success"]:
                        # ä¿å­˜æŠ€æœ¯æŒ‡æ ‡åˆ°æ•°æ®åº“
                        try:
                            latest_indicators = indicator_result["indicators"]
                            self.db_manager.execute(
                                """
                                INSERT OR REPLACE INTO technical_indicators 
                                (symbol, date, ma5, ma10, ma20, ma60, rsi_6, macd_dif, macd_dea, macd_histogram, boll_upper, boll_middle, boll_lower, calculated_at)
                                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now'))
                            """,
                                (
                                    symbol,
                                    str(target_date),
                                    latest_indicators.get("ma5", 0),
                                    latest_indicators.get("ma10", 0),
                                    latest_indicators.get("ma20", 0),
                                    latest_indicators.get("ma60", 0),
                                    latest_indicators.get("rsi", 0),
                                    latest_indicators.get("macd", 0),
                                    latest_indicators.get("macd_signal", 0),
                                    latest_indicators.get("macd_histogram", 0),
                                    latest_indicators.get("bollinger_upper", 0),
                                    latest_indicators.get("bollinger_middle", 0),
                                    latest_indicators.get("bollinger_lower", 0),
                                ),
                            )
                            result["indicators_count"] += 1
                            symbol_success = True
                        except Exception as e:
                            self.logger.warning(f"ä¿å­˜æŠ€æœ¯æŒ‡æ ‡å¤±è´¥ {symbol}: {e}")
                    else:
                        # æ ¹æ®å¤±è´¥åŸå› è°ƒæ•´æ—¥å¿—çº§åˆ«
                        message = indicator_result["message"]
                        if message == "recently_updated":
                            symbol_skipped = True
                            self.logger.debug(f"è·³è¿‡æŠ€æœ¯æŒ‡æ ‡è®¡ç®— {symbol}: æœ€è¿‘å·²æ›´æ–°")
                        elif "å†å²æ•°æ®ä¸è¶³" in message or "å†å²æ•°æ®ä¸ºç©º" in message:
                            self.logger.debug(f"è·³è¿‡æŠ€æœ¯æŒ‡æ ‡è®¡ç®— {symbol}: {message}")
                        else:
                            self.logger.debug(f"æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å¤±è´¥ {symbol}: {message}")

                except Exception as e:
                    self.logger.warning(f"è®¡ç®—æŠ€æœ¯æŒ‡æ ‡å¤±è´¥ {symbol}: {e}")
                    import traceback

                    self.logger.debug(f"æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")

                if symbol_success:
                    result["processed_symbols"] += 1
                elif symbol_skipped:
                    result["skipped_symbols"] += 1
                else:
                    result["failed_symbols"] += 1

                # æ›´æ–°è¿›åº¦æ¡
                if progress_bar:
                    progress_bar.update(1)

            except Exception as e:
                self.logger.error(f"å¤„ç†æ‰©å±•æ•°æ®å¤±è´¥ {symbol}: {e}")
                result["failed_symbols"] += 1
                result["errors"].append({"symbol": symbol, "error": str(e)})

                if progress_bar:
                    progress_bar.update(1)

        self.logger.info(
            f"ğŸ¯ æ‰©å±•æ•°æ®åŒæ­¥å®Œæˆ: "
            f"å¤„ç†{result['processed_symbols']}åª, "
            f"è·³è¿‡{result['skipped_symbols']}åª, "
            f"å¤±è´¥{result['failed_symbols']}åª"
        )

        return result

    def _auto_fix_gaps(self, gap_result: Dict[str, Any]) -> Dict[str, Any]:
        """è‡ªåŠ¨ä¿®å¤ç¼ºå£"""
        self.logger.info("å¼€å§‹è‡ªåŠ¨ä¿®å¤ç¼ºå£")

        fix_result = {
            "total_gaps": gap_result["summary"]["total_gaps"],
            "attempted_fixes": 0,
            "successful_fixes": 0,
            "failed_fixes": 0,
            "fix_details": [],
        }

        # è·å–ç¼ºå£è¯¦æƒ…
        gaps_by_symbol = gap_result.get("gaps_by_symbol", {})

        if not gaps_by_symbol:
            self.logger.info("æ²¡æœ‰å‘ç°ç¼ºå£ï¼Œæ— éœ€ä¿®å¤")
            return fix_result

        # é™åˆ¶ä¿®å¤æ•°é‡ï¼Œé¿å…è¿‡é•¿æ—¶é—´
        max_fixes = 20
        fixes_attempted = 0

        for symbol, symbol_gaps in gaps_by_symbol.items():
            if fixes_attempted >= max_fixes:
                self.logger.info(f"å·²è¾¾åˆ°æœ€å¤§ä¿®å¤æ•°é‡é™åˆ¶: {max_fixes}")
                break

            for gap in symbol_gaps.get("gaps", []):
                if fixes_attempted >= max_fixes:
                    break

                try:
                    gap_start = gap.get("gap_start")
                    gap_end = gap.get("gap_end")
                    frequency = gap.get("frequency", "1d")

                    if not gap_start or not gap_end:
                        continue

                    fix_result["attempted_fixes"] += 1
                    fixes_attempted += 1

                    self.logger.info(f"ä¿®å¤ç¼ºå£: {symbol} {gap_start} åˆ° {gap_end}")

                    # å°è¯•ä»æ•°æ®æºè·å–ç¼ºå£æœŸé—´çš„æ•°æ®
                    if frequency == "1d":
                        # è·å–æ—¥çº¿æ•°æ®å¡«è¡¥ç¼ºå£
                        daily_data = self.data_source_manager.get_daily_data(
                            symbol, gap_start, gap_end
                        )

                        if isinstance(daily_data, dict) and "data" in daily_data:
                            daily_data = daily_data["data"]

                        # æ£€æŸ¥è·å–åˆ°çš„æ•°æ®
                        if daily_data and hasattr(daily_data, "__len__"):
                            # å¦‚æœæ˜¯DataFrameæˆ–åˆ—è¡¨ï¼Œå¤„ç†æ•°æ®
                            records_inserted = 0

                            if hasattr(daily_data, "iterrows"):
                                # pandas DataFrame
                                for _, row in daily_data.iterrows():
                                    try:
                                        # ä½¿ç”¨æ•°æ®å¤„ç†å¼•æ“æ’å…¥æ•°æ®
                                        processed_result = (
                                            self.processing_engine.process_symbol_data(
                                                symbol,
                                                str(gap_start),
                                                str(gap_end),
                                                frequency,
                                            )
                                        )
                                        records_inserted += processed_result.get(
                                            "records", 0
                                        )
                                        break  # å¤„ç†å¼•æ“ä¼šå¤„ç†æ•´ä¸ªæ—¥æœŸèŒƒå›´
                                    except Exception as e:
                                        self.logger.warning(
                                            f"æ’å…¥ç¼ºå£æ•°æ®å¤±è´¥ {symbol}: {e}"
                                        )

                            if records_inserted > 0:
                                fix_result["successful_fixes"] += 1
                                fix_result["fix_details"].append(
                                    {
                                        "symbol": symbol,
                                        "gap_start": gap_start,
                                        "gap_end": gap_end,
                                        "records_inserted": records_inserted,
                                        "status": "success",
                                    }
                                )
                                self.logger.info(
                                    f"ç¼ºå£ä¿®å¤æˆåŠŸ: {symbol} æ’å…¥ {records_inserted} æ¡è®°å½•"
                                )
                            else:
                                fix_result["failed_fixes"] += 1
                                fix_result["fix_details"].append(
                                    {
                                        "symbol": symbol,
                                        "gap_start": gap_start,
                                        "gap_end": gap_end,
                                        "status": "failed",
                                        "reason": "æ— æ•°æ®å¯æ’å…¥",
                                    }
                                )
                        else:
                            fix_result["failed_fixes"] += 1
                            fix_result["fix_details"].append(
                                {
                                    "symbol": symbol,
                                    "gap_start": gap_start,
                                    "gap_end": gap_end,
                                    "status": "failed",
                                    "reason": "æ•°æ®æºæ— æ•°æ®",
                                }
                            )
                    else:
                        # å…¶ä»–é¢‘ç‡çš„ç¼ºå£ä¿®å¤æš‚ä¸å®ç°
                        fix_result["failed_fixes"] += 1
                        fix_result["fix_details"].append(
                            {
                                "symbol": symbol,
                                "gap_start": gap_start,
                                "gap_end": gap_end,
                                "status": "failed",
                                "reason": f"ä¸æ”¯æŒé¢‘ç‡ {frequency}",
                            }
                        )

                except Exception as e:
                    fix_result["failed_fixes"] += 1
                    fix_result["fix_details"].append(
                        {
                            "symbol": symbol,
                            "gap_start": gap.get("gap_start"),
                            "gap_end": gap.get("gap_end"),
                            "status": "error",
                            "reason": str(e),
                        }
                    )
                    self.logger.error(f"ä¿®å¤ç¼ºå£æ—¶å‘ç”Ÿé”™è¯¯ {symbol}: {e}")

        self.logger.info(
            f"ç¼ºå£ä¿®å¤å®Œæˆ: æ€»ç¼ºå£={fix_result['total_gaps']}, å°è¯•ä¿®å¤={fix_result['attempted_fixes']}, æˆåŠŸ={fix_result['successful_fixes']}, å¤±è´¥={fix_result['failed_fixes']}"
        )
        return fix_result

    def generate_sync_report(self, full_result: Dict[str, Any]) -> str:
        """ç”ŸæˆåŒæ­¥æŠ¥å‘Š"""
        try:
            report_lines = []

            # æŠ¥å‘Šå¤´éƒ¨
            report_lines.append("=" * 60)
            report_lines.append("æ•°æ®åŒæ­¥æŠ¥å‘Š")
            report_lines.append("=" * 60)
            report_lines.append(f"åŒæ­¥æ—¶é—´: {full_result.get('start_time', '')}")
            report_lines.append(f"ç›®æ ‡æ—¥æœŸ: {full_result.get('target_date', '')}")
            report_lines.append(
                f"æ€»è€—æ—¶: {full_result.get('duration_seconds', 0):.2f} ç§’"
            )
            report_lines.append("")

            # é˜¶æ®µæ±‡æ€»
            summary = full_result.get("summary", {})
            report_lines.append("é˜¶æ®µæ±‡æ€»:")
            report_lines.append(f"  æ€»é˜¶æ®µæ•°: {summary.get('total_phases', 0)}")
            report_lines.append(f"  æˆåŠŸé˜¶æ®µ: {summary.get('successful_phases', 0)}")
            report_lines.append(f"  å¤±è´¥é˜¶æ®µ: {summary.get('failed_phases', 0)}")
            report_lines.append("")

            # å„é˜¶æ®µè¯¦æƒ…
            phases = full_result.get("phases", {})

            # å¢é‡åŒæ­¥
            if "incremental_sync" in phases:
                phase = phases["incremental_sync"]
                report_lines.append("å¢é‡åŒæ­¥:")
                report_lines.append(f"  çŠ¶æ€: {phase['status']}")

                if phase["status"] == "completed" and "result" in phase:
                    result = phase["result"]
                    report_lines.append(f"  æ€»è‚¡ç¥¨æ•°: {result.get('total_symbols', 0)}")
                    report_lines.append(f"  æˆåŠŸæ•°é‡: {result.get('success_count', 0)}")
                    report_lines.append(f"  é”™è¯¯æ•°é‡: {result.get('error_count', 0)}")
                    report_lines.append(f"  è·³è¿‡æ•°é‡: {result.get('skipped_count', 0)}")
                elif "error" in phase:
                    report_lines.append(f"  é”™è¯¯: {phase['error']}")

                report_lines.append("")

            return "\n".join(report_lines)

        except Exception as e:
            self._log_error("generate_sync_report", e)
            return f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}"

    def _safe_get_attribute(self, obj, key: str, default=None):
        """å®‰å…¨è·å–å¯¹è±¡å±æ€§ï¼Œå…¼å®¹dictå’Œsqlite3.Row"""
        if obj is None:
            return default

        try:
            if hasattr(obj, "get"):
                return obj.get(key, default)
            elif hasattr(obj, "__getitem__"):
                return obj[key]
        except (KeyError, IndexError, TypeError):
            return default

        return default

    def _calculate_technical_indicators(
        self,
        symbol: str,
        target_date: date,
        indicator_calculator,
        existing_indicators: Dict[str, Any] = None,
    ) -> Dict[str, Any]:
        """
        è®¡ç®—å•ä¸ªè‚¡ç¥¨çš„æŠ€æœ¯æŒ‡æ ‡

        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            target_date: ç›®æ ‡æ—¥æœŸ
            indicator_calculator: æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å™¨
            existing_indicators: å·²å­˜åœ¨çš„æŒ‡æ ‡æ•°æ®

        Returns:
            Dict[str, Any]: è®¡ç®—ç»“æœ {"success": bool, "indicators": dict, "message": str}
        """
        from datetime import datetime, timedelta

        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
        daily_update_threshold = timedelta(days=1)
        if existing_indicators:
            try:
                # å®‰å…¨è·å– last_update å­—æ®µï¼Œå…¼å®¹ dict å’Œ sqlite3.Row
                last_update_value = self._safe_get_attribute(
                    existing_indicators, "last_update"
                )

                if last_update_value:
                    last_update = datetime.fromisoformat(
                        last_update_value.replace("Z", "+00:00")
                        if last_update_value.endswith("Z")
                        else last_update_value
                    )
                    if datetime.now() - last_update < daily_update_threshold:
                        return {
                            "success": False,
                            "message": "recently_updated",
                            "indicators": None,
                        }
            except Exception:
                pass  # å¦‚æœè§£ææ—¶é—´å¤±è´¥ï¼Œç»§ç»­è®¡ç®—

        # è·å–å†å²æ•°æ®
        start_date = target_date - timedelta(days=100)
        try:
            historical_data = self.data_source_manager.get_daily_data(
                symbol, start_date, target_date
            )
        except Exception as e:
            return {
                "success": False,
                "message": f"è·å–å†å²æ•°æ®å¤±è´¥: {e}",
                "indicators": None,
            }

        # å¤„ç†å†å²æ•°æ®æ ¼å¼
        processed_data = self._process_historical_data(historical_data)
        if not processed_data:
            return {
                "success": False,
                "message": "å†å²æ•°æ®ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯",
                "indicators": None,
            }

        # æ£€æŸ¥æ•°æ®é‡æ˜¯å¦è¶³å¤Ÿ
        data_length = self._get_data_length(processed_data)
        if data_length < 20:
            return {
                "success": False,
                "message": f"å†å²æ•°æ®ä¸è¶³({data_length}æ¡)",
                "indicators": None,
            }

        # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
        try:
            # ä¸´æ—¶é™ä½æ—¥å¿—çº§åˆ«ï¼Œé¿å…å¹²æ‰°è¿›åº¦æ¡
            indicators_logger = logging.getLogger(
                "simtradedata.preprocessor.indicators"
            )
            original_level = indicators_logger.level
            indicators_logger.setLevel(logging.ERROR)

            try:
                indicators_data = indicator_calculator.calculate_indicators(
                    processed_data, symbol
                )
            finally:
                indicators_logger.setLevel(original_level)

            if not indicators_data or not isinstance(indicators_data, dict):
                return {
                    "success": False,
                    "message": "æŠ€æœ¯æŒ‡æ ‡è®¡ç®—ç»“æœä¸ºç©º",
                    "indicators": None,
                }

            # æå–æœ€æ–°æŒ‡æ ‡å€¼
            latest_indicators = self._extract_latest_indicators(indicators_data)
            if not latest_indicators:
                return {
                    "success": False,
                    "message": "æ— æ³•æå–æœ€æ–°æŒ‡æ ‡å€¼",
                    "indicators": None,
                }

            return {
                "success": True,
                "message": "è®¡ç®—æˆåŠŸ",
                "indicators": latest_indicators,
            }

        except Exception as e:
            return {"success": False, "message": f"è®¡ç®—å¼‚å¸¸: {e}", "indicators": None}

    def _process_historical_data(self, historical_data) -> Any:
        """å¤„ç†å†å²æ•°æ®æ ¼å¼"""
        if historical_data is None:
            return None

        if isinstance(historical_data, dict) and "data" in historical_data:
            return historical_data["data"]

        return historical_data

    def _get_data_length(self, data) -> int:
        """è·å–æ•°æ®é•¿åº¦"""
        if hasattr(data, "__len__"):
            return len(data)
        elif hasattr(data, "shape"):
            return data.shape[0]
        return 0

    def _extract_latest_indicators(
        self, indicators_data: Dict[str, Any]
    ) -> Dict[str, float]:
        """æå–æœ€æ–°çš„æŒ‡æ ‡å€¼"""
        latest_indicators = {}
        for indicator_name, values in indicators_data.items():
            if isinstance(values, (list, tuple)) and len(values) > 0:
                latest_indicators[indicator_name] = values[-1]
            elif isinstance(values, (int, float)):
                latest_indicators[indicator_name] = values
        return latest_indicators
